{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a9b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/trapnell/vol1/home/mdcolon/software/miniconda3/envs/vae_env_cluster/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results directory: /net/trapnell/vol1/home/mdcolon/proj/morphseq/results/mcolon/20251013\n",
      "MORPHSEQ_REPO_ROOT: /net/trapnell/vol1/home/mdcolon/proj/morphseq\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Use the parent directory of this file for results\n",
    "# results_dir = os.getcwd()\n",
    "results_dir = \"/net/trapnell/vol1/home/mdcolon/proj/morphseq/results/mcolon/20251013\"\n",
    "data_dir = os.path.join(results_dir, \"data\")\n",
    "plot_dir = os.path.join(results_dir, \"plots\")\n",
    "\n",
    "print(f\"Results directory: {results_dir}\")\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "morphseq_root = os.environ.get('MORPHSEQ_REPO_ROOT')\n",
    "if morphseq_root is None:\n",
    "    morphseq_root = \"/net/trapnell/vol1/home/mdcolon/proj/morphseq\"\n",
    "\n",
    "print(f\"MORPHSEQ_REPO_ROOT: {morphseq_root}\")\n",
    "os.chdir(morphseq_root)\n",
    "\n",
    "# from src.functions.embryo_df_performance_metrics import *\n",
    "# from src.functions.spline_morph_spline_metrics import *\n",
    "\n",
    "# Import TZ experiments\n",
    "WT_experiments = [\"20230615\",\"20230531\", \"20230525\", \"20250912\"] \n",
    "\n",
    "b9d2_experiments = [\"20250519\",\"20250520\"]\n",
    "\n",
    "cep290_experiments = [\"20250305\", \"20250416\", \"20250512\", \"20250515_part2\", \"20250519\"]\n",
    "\n",
    "tmem67_experiments = [\"20250711\"]\n",
    "\n",
    "experiments = WT_experiments + b9d2_experiments + cep290_experiments + tmem67_experiments\n",
    "\n",
    "build06_dir = \"/net/trapnell/vol1/home/mdcolon/proj/morphseq/morphseq_playground/metadata/build06_output\"\n",
    "\n",
    "# Load all experiments\n",
    "dfs = []\n",
    "for exp in experiments:\n",
    "    try:\n",
    "        file_path = f\"{build06_dir}/df03_final_output_with_latents_{exp}.csv\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['source_experiment'] = exp\n",
    "        print(df['genotype'].value_counts())\n",
    "        dfs.append(df)\n",
    "        print(f\"Loaded {exp}: {len(df)} rows\")\n",
    "    except:\n",
    "        print(f\"Missing: {exp}\")\n",
    "\n",
    "# Combine all data\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"\\nTotal: {len(combined_df)} rows from {len(dfs)} experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0814332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_by_embryo_time(\n",
    "    df,\n",
    "    time_col=\"predicted_stage_hpf\",\n",
    "    z_cols=None,\n",
    "    bin_width=2.0,\n",
    "    suffix=\"_binned\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Bin VAE embeddings by predicted time and embryo.\n",
    "\n",
    "    Always averages embeddings per embryo_id × time_bin,\n",
    "    keeping all non-latent metadata columns (e.g., genotype).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe containing 'embryo_id', 'predicted_stage_hpf', and latent columns.\n",
    "    time_col : str\n",
    "        Column name to bin by.\n",
    "    z_cols : list or None\n",
    "        Columns to average. If None, auto-detect those containing 'z_mu_b'.\n",
    "    bin_width : float\n",
    "        Width of time bins (same units as time_col, usually hours).\n",
    "    suffix : str\n",
    "        Suffix to append to averaged latent column names.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        One row per (embryo_id, time_bin) containing averaged latent columns and preserved metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # detect latent columns\n",
    "    if z_cols is None:\n",
    "        z_cols = [c for c in df.columns if \"z_mu_b\" in c]\n",
    "        if not z_cols:\n",
    "            raise ValueError(\"No latent columns found matching pattern 'z_mu_b'.\")\n",
    "\n",
    "    # create time bins\n",
    "    df[\"time_bin\"] = (np.floor(df[time_col] / bin_width) * bin_width).astype(int)\n",
    "\n",
    "    # average latent vectors per embryo × time_bin\n",
    "    agg = (\n",
    "        df.groupby([\"embryo_id\", \"time_bin\"], as_index=False)[z_cols]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    # rename averaged latent columns\n",
    "    agg.rename(columns={c: f\"{c}{suffix}\" for c in z_cols}, inplace=True)\n",
    "\n",
    "    # merge back non-latent metadata (take first unique per embryo)\n",
    "    meta_cols = [c for c in df.columns if c not in z_cols + [time_col]]\n",
    "    meta_df = (\n",
    "        df[meta_cols]\n",
    "        .drop_duplicates(subset=[\"embryo_id\"])\n",
    "        .set_index(\"embryo_id\")\n",
    "    )\n",
    "\n",
    "    # merge metadata back in\n",
    "    out = agg.merge(meta_df, on=\"embryo_id\", how=\"left\")\n",
    "\n",
    "    # ensure sorting\n",
    "    out = out.sort_values([\"embryo_id\", \"time_bin\"]).reset_index(drop=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_z_columns(df, z_cols=None, suffix=\"_binned\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Identify latent (embedding) columns for analysis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe (already binned by embryo/time).\n",
    "    z_cols : list or None\n",
    "        Optional explicit list. If None, automatically detect by suffix or 'z_mu_b' pattern.\n",
    "    suffix : str\n",
    "        Column suffix used in binning (default '_binned').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Names of latent columns.\n",
    "    \"\"\"\n",
    "    if z_cols is None:\n",
    "        z_cols = [c for c in df.columns if c.endswith(suffix) or \"z_mu_b\" in c]\n",
    "    if not z_cols:\n",
    "        raise ValueError(\"No latent columns detected for analysis.\")\n",
    "    return z_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- helper stats --\n",
    "from itertools import combinations\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def energy_distance(X, Y):\n",
    "    XY = cdist(X, Y).mean()\n",
    "    XX = cdist(X, X).mean()\n",
    "    YY = cdist(Y, Y).mean()\n",
    "    return 2*XY - XX - YY\n",
    "\n",
    "def energy_perm_test(X, Y, n_perm=500, rng=None):\n",
    "    rng = np.random.default_rng(rng)\n",
    "    obs = energy_distance(X, Y)\n",
    "    Z = np.vstack([X, Y])\n",
    "    nx = len(X)\n",
    "    perm_stats = []\n",
    "    for _ in range(n_perm):\n",
    "        rng.shuffle(Z)\n",
    "        perm_stats.append(energy_distance(Z[:nx], Z[nx:]))\n",
    "    p = (np.sum(perm_stats >= obs) + 1) / (n_perm + 1)\n",
    "    return obs, p\n",
    "\n",
    "def hotellings_T2(X, Y):\n",
    "    n, m = len(X), len(Y)\n",
    "    mean_diff = X.mean(0) - Y.mean(0)\n",
    "    Sx = LedoitWolf().fit(X).covariance_\n",
    "    Sy = LedoitWolf().fit(Y).covariance_\n",
    "    Sp = ((n-1)*Sx + (m-1)*Sy) / (n+m-2)\n",
    "    invSp = np.linalg.pinv(Sp)\n",
    "    return (n*m)/(n+m) * float(mean_diff @ invSp @ mean_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c1714",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation_grounded_sam",
   "language": "python",
   "name": "segmentation_grounded_sam"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
