# Legacy Segmentation & Build Pipeline Overview

## 1. Introduction

This document provides a detailed description of the legacy `morphseq` image processing pipeline as implemented outside of the `segmentation_sandbox`. Its purpose is to take raw 2D or 3D brightfield image data, identify and segment key components like embryos and yolks, track embryos over time, perform quality control, and export processed image "snips" for downstream analysis.

Understanding this existing workflow is crucial for integrating new segmentation pipelines and for general project maintenance.

## 2. Core Dependencies

- **Environment:** The pipeline runs in the `torch-env` conda environment.
- **Key Libraries:**
    - `pytorch`: The core deep learning framework.
    - `pytorch-lightning`: Used as a high-level wrapper for the model definition.
    - `segmentation-models-pytorch`: Provides the Feature Pyramid Network (FPN) architecture and ResNet encoders. This is a critical dependency.
    - `scikit-image`: Used extensively for image manipulation (resizing, labeling, region properties).
    - `pandas`: Used for all metadata manipulation.
    - `nd2`: Used for reading raw `.nd2` z-stack files from the YX1 microscope.

## 3. Pipeline Flow

The pipeline is a multi-stage process, orchestrated by a series of `build` scripts. Each stage produces outputs that are consumed by the next.

---

### **Stage 1: Sequential Mask Generation**

This stage generates all the necessary segmentation masks for downstream processing. It does **not** use a single multi-target model, but rather a series of individual models run sequentially.

- **Script:** `src/build/build02B_segment_bf_main.py`
- **Entry Point:** The `apply_unet` function is the core worker. The `if __name__ == "__main__"` block calls this function four times in a row.

#### **Process:**

1.  **Model Definition:** The script uses the `FishModel` class defined in `src/functions/core_utils_segmentation.py`. This class implements a **Feature Pyramid Network (FPN)** with a **ResNet34** encoder backbone, provided by the `segmentation-models-pytorch` library.

2.  **Sequential Execution:** `apply_unet` is called once for each required mask, loading a different set of pre-trained weights each time. The typical execution order is:
    1.  **Embryo/Viability Segmentation** (`unet_emb_v4_0050`): A 2-class model to distinguish living vs. dead embryo regions.
    2.  **Bubble Segmentation** (`unet_bubble_v0_0050`): A 1-class model to identify air bubbles.
    3.  **Yolk Segmentation** (`unet_yolk_v0_0050`): A 1-class model to identify the embryo yolk.
    4.  **Focus Segmentation** (`unet_focus_v2_0050`): A 1-class model to identify out-of-focus regions.

#### **Inputs:**

-   **Images:** Raw 2D brightfield images (JPG, PNG, TIF) located in `built_image_data/stitched_FF_images/<experiment_date>/`.
-   **Model Weights:** Pre-trained `.pth` model files located in `segmentation/segmentation_models/`.

#### **Outputs:**

-   **Crucial Point:** Each model saves its predictions to a **separate directory**.
-   **Location:** `segmentation/<model_name>_predictions/<experiment_date>/`
-   **Format:** The output masks are single-channel 8-bit **JPG files**. They are **not** simple binary (0/255) masks. The pixel values are multi-level integers (e.g., 85, 170, 255) that encode class information based on the model's output probabilities. Downstream scripts must interpret these values correctly.

---

### **Stage 2: 2D Embryo Tracking and QC Analysis**

This stage takes the 2D masks from Stage 1, identifies and tracks individual embryos over time, and performs quality control checks.

- **Script:** `src/build/build03A_process_images.py`
- **Entry Points:** `segment_wells` followed by `compile_embryo_stats`.

#### **Process:**

1.  **Embryo Detection (`count_embryo_regions`):**
    -   Loads the embryo mask generated by `unet_emb_v4_0050`.
    -   **Implicit Binarization:** It converts the multi-level JPG mask into a binary mask using a mathematical operation that acts as a threshold (e.g., `(np.round(im / 255 * 2) - 1)`).
    -   Uses `skimage.measure.label` on the binarized mask to find distinct embryo objects.
    -   Extracts the centroid and a temporary `region_label` for each detected embryo.
    -   Uses the viability mask to calculate the `frac_alive` for each embryo.

2.  **Temporal Tracking (`do_embryo_tracking`):**
    -   Takes the per-frame embryo detections (centroids).
    -   Uses a linear sum assignment algorithm based on proximity to track each unique embryo over time, assigning it a stable `embryo_id`.

3.  **Quality Control (`get_embryo_stats`):**
    -   For each tracked embryo, this function loads the full set of masks from Stage 1 (embryo, yolk, bubble, focus).
    -   It uses the stored `region_label` to isolate the specific embryo of interest from the embryo mask.
    -   It performs a series of QC checks by comparing the embryo's location to the other masks, setting flags like `no_yolk_flag`, `focus_flag`, and `bubble_flag`.
    -   It calculates morphological statistics like `length_um`, `width_um`, and `surface_area_um`.

#### **Inputs:**

-   The various segmentation masks generated in Stage 1.

#### **Outputs:**

-   **Master Metadata File:** A rich CSV file (`embryo_metadata_df.csv`) containing a row for every detected embryo at every timepoint, including its ID, position, QC flags, and morphological stats. This file is the primary input for the final stage.

#### **Critical System Limitations:**

The legacy tracking system has several fundamental problems that make it fragile and computationally expensive:

1. **Fragile `region_label` System:**
   - Relies on `skimage.measure.label` to assign temporary region numbers to embryo blobs
   - Region labels are frame-specific and have no temporal consistency
   - Vulnerable to segmentation artifacts and touching objects

2. **Complex Tracking Algorithm:**
   - `do_embryo_tracking` uses linear sum assignment based on centroid proximity
   - Computationally intensive Hungarian algorithm for every frame
   - Prone to ID switching when embryos move close together or temporarily disappear

3. **Redundant Calculations:**
   - `get_embryo_stats` runs `skimage.measure.regionprops` to recalculate area, centroids, bounding boxes
   - These same properties could be pre-computed during segmentation
   - Results in duplicated computational effort and potential inconsistencies

4. **Error-Prone Pipeline:**
   - Multiple failure points: detection → labeling → tracking → statistics calculation
   - Silent failures possible at each stage (e.g., missed embryos, incorrect region isolation)
   - Difficult to debug when tracking fails partway through long time series

5. **Memory and Performance Issues:**
   - Must load and process multiple mask files for each embryo
   - Scales poorly with number of embryos and timepoints
   - No built-in validation or error recovery mechanisms

#### **Refactoring Implications for SAM2 Integration:**

The limitations above make Stage 2 the primary target for SAM2 integration. The refactoring strategy completely eliminates the problematic components:

**Functions to be DELETED entirely:**
- `count_embryo_regions()` - Replaced by SAM2's instance-aware masks
- `do_embryo_tracking()` - Replaced by SAM2's inherent temporal consistency  

**Function to be SIMPLIFIED:**
- `get_embryo_stats()` - Refactored from full property calculation to QC-only focus:
  - **REMOVE:** All regionprops calculations (area, centroid, bbox)
  - **REMOVE:** Region label isolation logic  
  - **KEEP:** QC flag calculations against U-Net masks (yolk, bubble, focus)
  - **KEEP:** Morphological measurements (length, width, surface area)
  - **NEW:** Accept CSV row as input instead of region_label

**Architecture Changes:**
- **Input Method:** Replace `glob.glob()` image discovery with `pd.read_csv()` as primary data source
- **Processing Logic:** Iterate over CSV rows instead of detected regions
- **Data Flow:** Pre-computed metadata → QC validation instead of detection → calculation
- **Error Handling:** CSV validation instead of mask parsing error handling

**Expected Outcomes:**
- **Code Reduction:** ~50-70% fewer lines in `build03A_process_images.py`
- **Performance Improvement:** 50-80% faster execution due to eliminated calculations
- **Reliability Improvement:** No more tracking failures or ID switching
- **Maintainability:** Clear separation of segmentation (SAM2) vs QC logic (legacy)

---

### **Stage 3: 3D Z-Stack Processing & Snippet Export**

The final stage uses the 2D tracking data to find the best focal plane in the original 3D image stacks and export high-quality 2D image snips.

- **Script:** `src/build/build03B_export_z_snips.py`
- **Entry Point:** `extract_embryo_z_snips`

#### **Process:**

1.  **Data Loading:**
    -   Loads the master metadata CSV produced by Stage 2.
    -   For a given embryo, it loads the original raw 3D image stack (either a `.nd2` file or a `.tif` stack).
    -   It also re-loads the 2D embryo and yolk masks from Stage 1.

2.  **Focus Calculation (`LoG_focus_stacker`):**
    -   **Critical Dependency:** To find the most in-focus z-slice, the script calculates focus scores (using a Laplacian of Gaussian filter) **only on the embryo "body"**.
    -   The body is defined by **subtracting the yolk mask from the embryo mask**. This means the yolk mask is essential for this calculation to work as intended.

3.  **Image Processing & Export (`export_embryo_snips_z`):**
    -   Once the optimal z-slice is found, the script orients the image using the embryo and yolk masks (`get_embryo_angle`).
    -   It rotates and crops a standardized "snip" from the selected z-slice.
    *   It saves the final processed 2D snip to `training_data/bf_embryo_snips_z<N>/`.

#### **Inputs:**

-   The metadata CSV from Stage 2.
-   The raw 3D image stacks (e.g., `.nd2` files).
-   The 2D embryo and yolk masks from Stage 1.

#### **Outputs:**

-   Final, processed, 2D brightfield image snips of each embryo, taken from the optimal focal plane.

---

## 4. SAM2 Segmentation Pipeline Advantages

The SAM2 (Segment Anything Model 2) segmentation pipeline, implemented in the `segmentation_sandbox`, provides a superior alternative to the legacy Stage 2 tracking system by addressing all major limitations.

### **Key Architectural Advantages:**

#### **1. Instance-Aware Masks**
- **Integer-Labeled Masks:** SAM2 outputs masks where pixel value directly corresponds to stable `embryo_id`
- **No Region Labeling:** Eliminates the fragile `skimage.measure.label` step entirely  
- **Consistent IDs:** Each embryo maintains the same pixel value across all frames in a video
- **Example:** All pixels for embryo `20240411_A01_e01` have value `1`, embryo `20240411_A01_e02` has value `2`

#### **2. Inherent Temporal Tracking**
- **Built-in Consistency:** SAM2 handles temporal tracking automatically during segmentation
- **No Hungarian Algorithm:** Eliminates complex linear sum assignment tracking
- **Robust to Movement:** Handles embryos moving close together or temporary occlusion
- **ID Stability:** No risk of ID switching mid-video

#### **3. Pre-Computed Metadata**
- **Rich Annotations:** SAM2 outputs include area, bounding box, mask confidence for each embryo
- **No Regionprops:** Eliminates redundant area/centroid calculations in build scripts
- **Consistent Measurements:** All metrics calculated from same source masks
- **Performance Gain:** ~50-80% reduction in computational time for metadata extraction

#### **4. Comprehensive Output Format**
SAM2 produces `GroundedSam2Annotations.json` with complete embryo metadata:
```json
{
    "embryos": {
        "20240411_A01_e01": {
            "snip_id": "20240411_A01_e01_s0042",
            "area": 5000.0,
            "bbox": [0.1, 0.2, 0.3, 0.4], 
            "mask_confidence": 0.95,
            "segmentation": {"counts": "RLE_string", "size": [1024, 1024]}
        }
    }
}
```

### **ID Format Compatibility:**

#### **Native SAM2 Format:**
- **snip_id:** Uses `_s` prefix (e.g., `20240411_A01_e01_s0042`) 
- **Frame Indexing:** `frame_index` matches snip numbering for parsing consistency
- **No Conversion Needed:** Analysis confirmed frame_index == time_int, so `_s` format works directly

#### **Parsing Integration:**
- **Existing Utilities:** `parsing_utils.py` handles both `_s` and `_t` formats
- **ID Extraction:** All existing ID parsing functions work with SAM2 native format
- **Well Mapping:** SAM2 embryo_ids trace back to well IDs for metadata integration

## 5. SAM2 Integration Strategy

The integration of SAM2 into the legacy pipeline follows a **metadata bridge architecture** that transforms build scripts from data-processors into data-consumers.

### **Core Integration Principle:**

**From Producer to Consumer:** Instead of having build scripts calculate embryo properties from raw masks, they consume pre-computed metadata from SAM2's rich output format.

### **Two-Phase Implementation:**

#### **Phase 1: Metadata Bridge Script**
- **Script:** `segmentation_sandbox/scripts/utils/export_sam2_metadata_to_csv.py`
- **Purpose:** Flatten nested `GroundedSam2Annotations.json` into build-script-friendly CSV
- **Input:** SAM2 JSON with nested experiment → video → image → embryo structure
- **Output:** Flat CSV with one row per embryo per frame

**CSV Schema:**
```
image_id, embryo_id, snip_id, frame_index, area_px, 
bbox_x_min, bbox_y_min, bbox_x_max, bbox_y_max, 
mask_confidence, exported_mask_path, experiment_id, 
video_id, is_seed_frame
```

#### **Phase 2: Build Script Refactoring** 
- **Target:** `src/build/build03A_process_images.py`
- **Architecture Change:** CSV-driven processing instead of glob-based image discovery
- **Function Elimination:** Remove `count_embryo_regions`, `do_embryo_tracking` entirely
- **Function Simplification:** Refactor `get_embryo_stats` to focus only on QC checks

### **Data Flow Transformation:**

**Legacy Flow:**
```
Raw Images → Mask Generation → Region Labeling → 
Tracking Algorithm → Property Calculation → QC Analysis
```

**SAM2 Integration Flow:**
```
GroundedSam2Annotations.json → CSV Bridge → 
Pre-computed Metadata Loading → QC Analysis Only
```

### **Risk Mitigation Strategies:**

#### **1. Schema Validation**
- JSON structure validation with version checks
- CSV schema enforcement with type checking
- Graceful handling of missing or malformed fields

#### **2. File System Robustness**
- Exported mask file existence validation
- Clear error messages for missing dependencies
- Fallback mechanisms for partial data

#### **3. Performance Optimization**
- DataFrame operations optimization for large datasets
- Memory-efficient processing for multi-experiment batches
- Benchmark targets: Bridge <30s, Build <2x legacy time

#### **4. Backward Compatibility**
- Maintain existing output schema for downstream tools
- Preserve QC flag calculations and thresholds
- Keep well metadata integration unchanged

### **Integration Benefits:**

1. **Complexity Reduction:** ~50% code reduction in build scripts
2. **Reliability Improvement:** Eliminates fragile tracking algorithm 
3. **Performance Gains:** Pre-computed metadata eliminates redundant calculations
4. **Maintainability:** Clear separation between segmentation and QC logic
5. **Scalability:** Better handling of large multi-experiment datasets

---

### **Well Metadata Integration System**

The legacy pipeline includes a sophisticated well metadata system that provides biological context (genotype, treatments, phenotypes) separate from the image processing pipeline.

#### **File Structure:**

- **Location:** `metadata/plate_metadata/{experiment_date}_well_metadata.xlsx`
- **Format:** Multi-sheet Excel files with standardized 96-well plate layout

#### **Excel Sheet Structure:**

Each Excel file contains multiple sheets defining experimental conditions:

1. **`medium`** - Culture medium specifications per well
2. **`genotype`** - Genetic background and mutations per well  
3. **`chem_perturbation`** - Chemical treatments and dosages
4. **`start_age_hpf`** - Starting age in hours post fertilization
5. **`embryos_per_well`** - Number of embryos per well
6. **`temperature`** - Incubation temperature per well
7. **`qc`** (optional) - Well-level quality control flags

#### **Processing Pipeline:**

- **Primary Function:** `load_experiment_plate_metadata()` in `src/build/export_utils.py`
- **Process:**
  1. Loads Excel file using `pd.ExcelFile()`
  2. Parses each sheet into 8×12 well layout (A01-H12)
  3. Flattens 2D plate data into long-format DataFrame
  4. Creates well-level metadata with one row per well per experiment
  5. Merges with embryo tracking data based on well ID matching

#### **Integration Points:**

- **Early Stage:** Used in `build01B_compile_yx1_images_torch.py` during initial image compilation
- **Export Stage:** Primary integration happens during final data export via `export_utils.py`
- **QC Analysis:** Referenced in `build04_perform_embryo_qc.py` for phenotype-based quality control

#### **Key Design Principles:**

- **Separation of Concerns:** Well metadata (biological context) is completely separate from image processing pipeline
- **Well-Based Matching:** Integration occurs via well ID (e.g., "A01") rather than individual embryo IDs
- **Plate-Level Organization:** Each Excel file represents one experimental plate with standardized layout
- **Flexible Schema:** Different experiments can have different combinations of treatments and conditions

#### **Implications for SAM2 Integration:**

- **No Direct Interaction:** SAM2 bridge script should focus purely on segmentation metadata
- **Existing Integration Path:** Well metadata merging is handled by established functions in `export_utils.py`
- **ID Compatibility:** SAM2 embryo IDs must be traceable back to well IDs for proper metadata integration
- **Parallel Processing:** Well metadata and segmentation metadata can be processed independently and merged downstream
