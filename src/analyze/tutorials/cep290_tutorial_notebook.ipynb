{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEP290 Cross-Experiment Analysis Tutorial\n",
    "\n",
    "End-to-end analysis of CEP290 crispant experiments using `src/analyze`.\n",
    "\n",
    "**Pipeline**: Feature plotting → PCA → DTW clustering → Cross-experiment projection → Classification tests\n",
    "\n",
    "**Data**: Two CEP290 crispant experiments (20260122, 20260124) from `build06_output` (includes curvature metrics + VAE latents) plus previously performed cluster labels from 20251229_cep290_phenotype_extraction file\n",
    "\n",
    "**Note**: Bootstrap/permutation counts are reduced for speed (`n_bootstrap=20`, `n_permutations=50`). For production analyses, increase `n_bootstrap` to 100+ and `n_permutations` to 200+.\n",
    "\n",
    "**Performance**: Several steps (`compute_trajectory_distances`, `run_k_selection_with_plots`, `run_bootstrap_projection_with_plots`, `run_classification_test`) support `n_jobs=-1` for automatic multi-CPU parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup & Data Loading\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Project paths — assumes notebook is run from src/analyze/tutorials/\n",
    "TUTORIAL_DIR = Path.cwd()\n",
    "project_root = TUTORIAL_DIR.parents[2]  # tutorials → analyze → src → repo root\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "OUTPUT_DIR = TUTORIAL_DIR / \"output\"\n",
    "FIGURES_DIR = OUTPUT_DIR / \"figures\" / \"notebook\"\n",
    "RESULTS_DIR = OUTPUT_DIR / \"results\"\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Data Loading ---\n",
    "# Two approaches available:\n",
    "\n",
    "# Option 1: Use load_experiments() utility (loads multiple experiments at once)\n",
    "from analyze.utils.data_loading import load_experiments\n",
    "\n",
    "build_dir = project_root / \"morphseq_playground\" / \"metadata\" / \"build06_output\"\n",
    "df = load_experiments( experiment_ids=[\"20260122\", \"20260124\"], build_dir=build_dir, verbose=True)\n",
    "\n",
    "# Extract source_dfs dict for later use (e.g., per-experiment projection)\n",
    "source_dfs = {exp_id: df[df[\"source_experiment\"] == exp_id].copy() \n",
    "              for exp_id in df[\"source_experiment\"].unique()}\n",
    "\n",
    "# Option 2: Manual loading (commented out — use if you need custom control)\n",
    "# data_dir = project_root / \"morphseq_playground\" / \"metadata\" / \"build06_output\"\n",
    "# source_dfs = {}\n",
    "# for exp_id in [\"20260122\", \"20260124\"]:\n",
    "#     df_exp = pd.read_csv(data_dir / f\"df03_final_output_with_latents_{exp_id}.csv\", low_memory=False)\n",
    "#     df_exp = df_exp[df_exp[\"use_embryo_flag\"]].copy()\n",
    "#     df_exp[\"experiment_id\"] = exp_id\n",
    "#     source_dfs[exp_id] = df_exp\n",
    "# df = pd.concat(source_dfs.values(), ignore_index=True)\n",
    "\n",
    "print(f\"\\nLoaded {df['embryo_id'].nunique()} embryos, {len(df)} timepoints\")\n",
    "print(f\"Experiments: {sorted(df['experiment_id'].unique())}\")\n",
    "print(f\"Genotypes: {sorted(df['genotype'].unique())}\")\n",
    "print(f\"Time range: {df['predicted_stage_hpf'].min():.1f}–{df['predicted_stage_hpf'].max():.1f} hpf\")\n",
    "\n",
    "# Shared color palette\n",
    "from analyze.trajectory_analysis.viz.styling import get_color_for_genotype\n",
    "\n",
    "color_lookup = {gt: get_color_for_genotype(gt) for gt in df[\"genotype\"].unique()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature-Over-Time Plotting\n",
    "\n",
    "most efficient way to look at features overtime (e.g. curvsture, embedding distance, etc) is to plot them over time with one line per embryo and a smoothed trend line. This allows you to see both the overall trend and the variability across embryos.\n",
    "\n",
    "`plot_feature_over_time(df, features, ...)` plots one or more metrics over developmental time with per-embryo traces and a smoothed trend line.\n",
    "\n",
    "**Key parameters:**\n",
    "\n",
    "| Parameter | Default | Description |\n",
    "|---|---|---|\n",
    "| `features` | *(required)* | `str` or `list[str]`. Single feature plots one panel; a list creates one row per feature. |\n",
    "| `color_by` | `None` | Column to color traces by (e.g. `\"genotype\"`, `\"pair\"`). |\n",
    "| `color_lookup` | `None` | `dict` mapping `color_by` values to hex colors. Auto-assigns if omitted. |\n",
    "| `facet_row` | `None` | Column to split into subplot rows (e.g. `\"experiment_id\"`). |\n",
    "| `facet_col` | `None` | Column to split into subplot columns (e.g. `\"genotype\"`). |\n",
    "| `backend` | `\"plotly\"` | `\"plotly\"` (interactive), `\"matplotlib\"` (static), or `\"both\"` (returns dict). |\n",
    "| `show_individual` | `True` | Show per-embryo trajectory lines. |\n",
    "| `show_error_band` | `False` | Show error band around trend line. |\n",
    "| `error_type` | `\"iqr\"` | Error measure: `\"iqr\"`/`\"mad\"` for median, `\"sd\"`/`\"se\"` for mean. |\n",
    "| `trend_statistic` | `\"median\"` | Central tendency: `\"median\"` or `\"mean\"`. |\n",
    "| `trend_smooth_sigma` | `1.5` | Gaussian smoothing sigma for the trend line. |\n",
    "| `bin_width` | `0.5` | Time bin width (hpf) for aggregating the trend. |\n",
    "| `smooth_method` | `\"gaussian\"` | Smoothing for individual traces (`None` to disable). |\n",
    "\n",
    "**Return value:** With `backend=\"both\"`, returns `{\"plotly\": fig, \"matplotlib\": fig}`. Otherwise returns a single figure.\n",
    "\n",
    "**Faceting behavior:** When `features` is a list, each feature becomes its own row automatically. `facet_row` and `facet_col` add additional grid dimensions from data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze.viz.plotting import plot_feature_over_time\n",
    "\n",
    "# Example 1: Single feature — curvature by genotype (both backends)\n",
    "figs = plot_feature_over_time(\n",
    "    df,\n",
    "    features=\"baseline_deviation_normalized\",\n",
    "    color_by=\"genotype\",\n",
    "    color_lookup=color_lookup,\n",
    "    backend=\"both\",\n",
    ")\n",
    "figs[\"plotly\"].write_html(FIGURES_DIR / \"notebook_01_curvature.html\")\n",
    "figs[\"plotly\"].show()\n",
    "figs[\"matplotlib\"].savefig(FIGURES_DIR / \"notebook_01_curvature.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Example 2: Faceted — rows by experiment, columns by genotype, colored by pair\n",
    "figs = plot_feature_over_time(\n",
    "    df,\n",
    "    features=\"baseline_deviation_normalized\",\n",
    "    facet_row=\"experiment_id\",\n",
    "    facet_col=\"genotype\",\n",
    "    color_by=\"pair\",\n",
    "    backend=\"matplotlib\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Example 3: Multi-feature faceted (curvature + length × genotype)\n",
    "figs = plot_feature_over_time(\n",
    "    df,\n",
    "    features=[\"baseline_deviation_normalized\", \"total_length_um\"],\n",
    "    color_by=\"genotype\",\n",
    "    color_lookup=color_lookup,\n",
    "    facet_col=\"genotype\",\n",
    "    backend=\"matplotlib\",\n",
    ")\n",
    "plt.savefig(FIGURES_DIR / \"notebook_01_multi_feature.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature-over-time plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA & 3D Scatter\n",
    "\n",
    "Reduce VAE latent dimensions with PCA and visualize embryo trajectories in 3D space. `fit_transform_pca()` auto-detects `z_mu_b_*` columns; `plot_3d_scatter()` supports both categorical and continuous coloring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze.utils import fit_transform_pca\n",
    "from analyze.viz.plotting import plot_3d_scatter\n",
    "\n",
    "df_pca, pca, scaler, z_mu_cols = fit_transform_pca(df, n_components=3)\n",
    "pca_cols = [\"PCA_1\", \"PCA_2\", \"PCA_3\"]\n",
    "\n",
    "var = pca.explained_variance_ratio_\n",
    "print(f\"PCA variance explained: PC1={var[0]*100:.1f}%, PC2={var[1]*100:.1f}%, PC3={var[2]*100:.1f}% (total={var.sum()*100:.1f}%)\")\n",
    "\n",
    "# 3D scatter colored by genotype\n",
    "fig = plot_3d_scatter(\n",
    "    df_pca,\n",
    "    coords=pca_cols,\n",
    "    color_by=\"genotype\",\n",
    "    color_palette=color_lookup,\n",
    "    show_lines=False,\n",
    "    show_mean=False,\n",
    ")\n",
    "fig.write_html(FIGURES_DIR / \"notebook_02_pca_3d.html\")\n",
    "fig.show()\n",
    "\n",
    "# 3D scatter colored by developmental time\n",
    "fig_time = plot_3d_scatter(\n",
    "    df_pca,\n",
    "    coords=pca_cols,\n",
    "    color_by=\"predicted_stage_hpf\",\n",
    "    color_continuous=True,\n",
    "    colorscale=\"Viridis\",\n",
    "    colorbar_title=\"predicted_stage_hpf\",\n",
    "    show_lines=False,\n",
    "    show_mean=False,\n",
    "    hover_cols=[\"genotype\", \"experiment_id\"],\n",
    ")\n",
    "fig_time.write_html(FIGURES_DIR / \"notebook_02_pca_3d_by_time.html\")\n",
    "fig_time.show()\n",
    "\n",
    "print(\"PCA scatter saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTW Clustering\n",
    "\n",
    "Cluster embryo trajectories by shape similarity using MD-DTW distance and k-medoids.\n",
    "\n",
    "**Pipeline:**\n",
    "`HPF Coverage Check` → `Distance Matrix` → `K-Selection` → `Apply Clusters`\n",
    "\n",
    "| Step | Function | Key Parameters |\n",
    "|------|----------|---------------|\n",
    "| 1. HPF overlap | `plot_experiment_time_coverage()` + `plot_hpf_overlap_quick()` | `bin_width=0.5`, `min_embryos_per_bin=3`, `min_experiments=2` |\n",
    "| 2. Distance matrix | `compute_trajectory_distances()` | `metrics` (one or more features), `time_window`, `normalize=True`, `sakoe_chiba_radius=20` |\n",
    "| 3. K-selection | `run_k_selection_with_plots()` | `k_range`, `n_bootstrap` (20 for speed, 100+ for production), `method=\"kmedoids\"` |\n",
    "\n",
    "**Hints:**\n",
    "- **HPF window**: Auto-detection can be unreliable with batch effects — override manually if needed.\n",
    "- **Features**: `metrics` accepts a single feature or a list. A single feature gives standard DTW; a list gives multidimensional DTW (e.g. curvature + length jointly).\n",
    "- **Warping**: `sakoe_chiba_radius=20` constrains alignment flexibility. Lower = stricter temporal matching.\n",
    "- **Speed**: `n_bootstrap=20` is fast for exploration. Use 100+ for publication figures. Distance matrix and k-selection both support `n_jobs=-1` for multi-CPU parallelization.\n",
    "- **Output**: `cluster_assignments.csv` contains labels for every k in `k_range`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze.trajectory_analysis.utilities.dtw_utils import compute_trajectory_distances\n",
    "from analyze.trajectory_analysis.clustering import run_k_selection_with_plots\n",
    "from analyze.viz.hpf_coverage import plot_experiment_time_coverage, plot_hpf_overlap_quick\n",
    "\n",
    "# HPF coverage check\n",
    "bins_mid, cover_df, cov_count = plot_experiment_time_coverage(\n",
    "    df, experiment_col=\"experiment_id\", hpf_col=\"predicted_stage_hpf\",\n",
    "    embryo_col=\"embryo_id\", bin_width=0.5, min_embryos_per_bin=3,\n",
    ")\n",
    "hpf_start, hpf_end = plot_hpf_overlap_quick(\n",
    "    bins_mid, cov_count, cover_df=cover_df, min_experiments=2,\n",
    "    show_heatmap=True,\n",
    "    coverage_plot_path=FIGURES_DIR / \"notebook_03_hpf_coverage.png\",\n",
    "    heatmap_path=FIGURES_DIR / \"notebook_03_hpf_heatmap.png\",\n",
    "    show=True,\n",
    ")\n",
    "# Override — batch effects in staging can make auto-detection unreliable\n",
    "hpf_start, hpf_end = 25, 50\n",
    "time_window = (hpf_start, hpf_end)\n",
    "print(f\"HPF window: {hpf_start}–{hpf_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MD-DTW distance matrix\n",
    "FEATURES = [\"baseline_deviation_normalized\"]\n",
    "D, embryo_ids, time_grid = compute_trajectory_distances(\n",
    "    df, \n",
    "    metrics=FEATURES, \n",
    "    time_col=\"predicted_stage_hpf\",\n",
    "    time_window=time_window, \n",
    "    embryo_id_col=\"embryo_id\",\n",
    "    normalize=True,\n",
    "    sakoe_chiba_radius=20, \n",
    "    verbose=True,\n",
    ")\n",
    "print(f\"Distance matrix: {D.shape}, range [{D.min():.2f}, {D.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Selection\n",
    "\n",
    "Run bootstrap stability analysis to choose the optimal number of clusters.\n",
    "\n",
    "**Key parameters:**\n",
    "- `method`: Clustering algorithm. Options: `\"kmedoids\"` (preferred, robust to outliers) or `\"hierarchical\"`.\n",
    "- `n_bootstrap`: Number of bootstrap resamples for stability analysis. Use 20 for exploration, 100+ for production.\n",
    "- `k_range`: List of k values to test (e.g., `[2, 3, 4, 5, 6]`).\n",
    "- `plotting_metrics`: Features to plot in cluster trajectories (can differ from distance metrics).\n",
    "- `enable_stage1_filtering`: Whether to apply outlier filtering before clustering (default: `True`).\n",
    "- `stage1_method`: Outlier detection method (`\"iqr\"` or `\"knn\"`). Default: `\"iqr\"`.\n",
    "\n",
    "**Outputs saved to `output_dir`:**\n",
    "- `cluster_assignments.csv`: Cluster labels for all k values tested\n",
    "- `silhouette_scores.png`: Silhouette scores by k\n",
    "- `stability_heatmap.png`: Bootstrap stability matrix\n",
    "- `cluster_flow_sankey.html`: Interactive Sankey diagram showing cluster reassignments across k\n",
    "- `k_{k}/`: Per-k subdirectories with trajectory plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-selection (reduced bootstrap for speed)\n",
    "df_filtered = df[df[\"embryo_id\"].isin(embryo_ids)].copy()\n",
    "k_selection_dir = FIGURES_DIR / \"notebook_03_k_selection\"\n",
    "\n",
    "k_results = run_k_selection_with_plots(\n",
    "    df=df_filtered, D=D, embryo_ids=embryo_ids,\n",
    "    output_dir=k_selection_dir,\n",
    "    k_range=[2, 3, 4, 5, 6],\n",
    "    n_bootstrap=20,  # Production: use 100+\n",
    "    method=\"kmedoids\",\n",
    "    plotting_metrics=[\"baseline_deviation_normalized\", \"total_length_um\"],\n",
    "    x_col=\"predicted_stage_hpf\",\n",
    "    iqr_multiplier=2, verbose=True,\n",
    ")\n",
    "\n",
    "# Inspect returned object structure\n",
    "print(f\"\\nBest k: {k_results['best_k']}\")\n",
    "print(f\"K values tested: {k_results['k_values']}\")\n",
    "print(f\"\\nReturn object keys: {list(k_results.keys())}\")\n",
    "\n",
    "# Example: Access cluster assignments for k=3\n",
    "k3_data = k_results['clustering_by_k'][3]\n",
    "print(f\"\\nk=3 structure: {list(k3_data.keys())}\")\n",
    "print(f\"  - quality metrics: {list(k3_data['quality'].keys())}\")\n",
    "print(f\"  - assignments: {list(k3_data['assignments'].keys())}\")\n",
    "print(f\"  - membership: {list(k3_data['membership'].keys())}\")\n",
    "\n",
    "# Example: Get embryo-to-cluster mapping for k=3\n",
    "embryo_to_cluster = k3_data['assignments']['embryo_to_cluster']\n",
    "print(f\"\\nFirst 5 embryo→cluster assignments (k=3): {dict(list(embryo_to_cluster.items())[:5])}\")\n",
    "\n",
    "# Example: Get all embryos in cluster 0 at k=3\n",
    "cluster_0_embryos = k3_data['assignments']['cluster_to_embryos'][0]\n",
    "print(f\"\\nCluster 0 contains {len(cluster_0_embryos)} embryos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Clusters\n",
    "\n",
    "Choose your k from the selection above, or subset and recluster as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply k=3 clusters to full dataframe\n",
    "cluster_assignments = pd.read_csv(k_selection_dir / \"cluster_assignments.csv\")\n",
    "df_clustered = df.merge(\n",
    "    cluster_assignments[[\"embryo_id\", \"clustering_k_3\"]],\n",
    "    on=\"embryo_id\", how=\"left\",\n",
    ").rename(columns={\"clustering_k_3\": \"cluster\"})\n",
    "\n",
    "clustered_path = RESULTS_DIR / \"notebook_df_clustered_k3.csv\"\n",
    "df_clustered.to_csv(clustered_path, index=False)\n",
    "print(\"K-selection + clustering saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Experiment Projection\n",
    "\n",
    "Project new embryos onto well-characterized reference clusters using bootstrap DTW nearest-neighbor classification. This assigns each embryo a cluster label with confidence scores (max_p, entropy).\n",
    "\n",
    "Reference clusters come from 7 CEP290 experiments analyzed in `20251229_cep290_phenotype_extraction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze.trajectory_analysis import run_bootstrap_projection_with_plots\n",
    "from analyze.viz.plotting import plot_proportions\n",
    "\n",
    "# Load reference cluster definitions (CEP290 mutants, 7 experiments)\n",
    "CEP290_REF_DIR = (\n",
    "    project_root / \"results\" / \"mcolon\"\n",
    "    / \"20251229_cep290_phenotype_extraction\" / \"final_data\"\n",
    ")\n",
    "df_ref_data = pd.read_csv(CEP290_REF_DIR / \"embryo_data_with_labels.csv\", low_memory=False)\n",
    "labels_valid = pd.read_csv(CEP290_REF_DIR / \"embryo_cluster_labels.csv\", low_memory=False)\n",
    "labels_valid = labels_valid.drop_duplicates(subset=\"embryo_id\")\n",
    "labels_valid = labels_valid[labels_valid[\"cluster_categories\"].notna()].copy()\n",
    "\n",
    "df_ref = df_ref_data[df_ref_data[\"embryo_id\"].isin(labels_valid[\"embryo_id\"])].copy()\n",
    "\n",
    "print(f\"Reference: {df_ref['embryo_id'].nunique()} embryos\")\n",
    "print(f\"Clusters: {labels_valid['cluster_categories'].value_counts().to_dict()}\")\n",
    "\n",
    "# Project each experiment onto reference (combined approach)\n",
    "df_combined = pd.concat(source_dfs.values(), ignore_index=True)\n",
    "\n",
    "PROJECTION_DIR = FIGURES_DIR / \"notebook_04_projection\"\n",
    "projection_results = run_bootstrap_projection_with_plots(\n",
    "    source_df=df_combined,\n",
    "    reference_df=df_ref,\n",
    "    labels_df=labels_valid,\n",
    "    output_dir=PROJECTION_DIR,\n",
    "    run_name=\"combined_projection\",\n",
    "    id_col=\"embryo_id\",\n",
    "    time_col=\"predicted_stage_hpf\",\n",
    "    cluster_col=\"cluster_categories\",\n",
    "    category_col=None,\n",
    "    metrics=[\"baseline_deviation_normalized\"],\n",
    "    sakoe_chiba_radius=20,\n",
    "    n_bootstrap=20,  # Production: use 100+\n",
    "    frac=0.8,\n",
    "    bootstrap_on=\"reference\",\n",
    "    method=\"nearest_neighbor\",\n",
    "    classification=\"2d\",\n",
    "    normalize=True,\n",
    "    verbose=True,\n",
    "    save_outputs=True,\n",
    ")\n",
    "\n",
    "df_proj = projection_results[\"assignments_df\"]\n",
    "genotype_map = dict(zip(df_combined[\"embryo_id\"], df_combined[\"genotype\"]))\n",
    "experiment_map = dict(zip(df_combined[\"embryo_id\"], df_combined[\"experiment_id\"]))\n",
    "df_proj[\"genotype\"] = df_proj[\"embryo_id\"].map(genotype_map)\n",
    "df_proj[\"experiment_id\"] = df_proj[\"embryo_id\"].map(experiment_map)\n",
    "\n",
    "# Save projection results\n",
    "df_proj.to_csv(PROJECTION_DIR / \"combined_projection_bootstrap.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion summary\n",
    "print(\"\\nCluster proportions by genotype:\")\n",
    "prop = df_proj.groupby(\"genotype\")[\"cluster_label\"].value_counts(normalize=True).unstack(fill_value=0)\n",
    "print((prop * 100).round(1))\n",
    "\n",
    "# Proportion plot by experiment and genotype\n",
    "df_embryo_proj = df_proj.drop_duplicates(subset=\"embryo_id\")\n",
    "fig = plot_proportions(\n",
    "    df_embryo_proj,\n",
    "    color_by_grouping=\"cluster_label\",\n",
    "    row_by=\"genotype\",\n",
    "    col_by=\"experiment_id\",\n",
    "    count_by=\"embryo_id\",\n",
    "    normalize=True,\n",
    "    bar_mode=\"grouped\",\n",
    "    title=\"Cluster Distribution by Experiment and Genotype\",\n",
    "    show_counts=True,\n",
    ")\n",
    "plt.savefig(FIGURES_DIR / \"notebook_04_proportion_by_experiment.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Trajectory plot colored by cluster label\n",
    "df_proj_merged = df_combined.merge(\n",
    "    df_proj[[\"embryo_id\", \"cluster_label\"]].drop_duplicates(),\n",
    "    on=\"embryo_id\", how=\"inner\"\n",
    ")\n",
    "\n",
    "# Define cluster colors (consistent with classification section)\n",
    "fig = plot_feature_over_time(\n",
    "    df_proj_merged,\n",
    "    features=[\"baseline_deviation_normalized\"],\n",
    "    color_by=\"cluster_label\",\n",
    "    facet_col=\"genotype\",\n",
    "    backend=\"matplotlib\",\n",
    "    title=\"Projected Cluster Labels by Genotype\",\n",
    ")\n",
    "plt.savefig(FIGURES_DIR / \"notebook_04_trajectories_by_cluster.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Cross-experiment projection saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Tests\n",
    "\n",
    "Run permutation-based classification tests to quantify phenotypic differences between clusters:\n",
    "- **Mode 1: One-vs-Rest** — How distinguishable is each cluster from all others?\n",
    "- **Mode 2: vs Not Penetrant** — How different is each mutant cluster from wild-type-like embryos?\n",
    "- **Mode 3: Crispant vs Homozygous (negative control)** — Within the same phenotypic cluster, crispants and homozygous mutants should be indistinguishable (AUROC ~0.5).\n",
    "- **Mode 4: ab vs Wildtype (negative control)** — Two wildtype strains from different genetic backgrounds should also be indistinguishable (AUROC ~0.5).\n",
    "\n",
    "Three feature sets are compared: curvature, body length, and VAE embedding.\n",
    "\n",
    "Permutation count is reduced for speed (`n_permutations=50`). For production, use 200+.\n",
    "\n",
    "**Caveat**: Modes 3/4 combine data across experiments. VAE batch effects inflate embedding AUROCs (~0.8) even for expected-null comparisons. Curvature-only controls are more reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze.difference_detection import run_classification_test\n",
    "from analyze.difference_detection.classification_test_viz import (\n",
    "    plot_feature_comparison_grid,\n",
    "    plot_multiple_aurocs,\n",
    ")\n",
    "\n",
    "# Load projection labels — use build06 data (has z_mu_b latents)\n",
    "proj_labels = df_proj[[\"embryo_id\", \"cluster_label\", \"membership\"]].drop_duplicates(subset=\"embryo_id\")\n",
    "df_target = df.merge(proj_labels, on=\"embryo_id\", how=\"inner\")\n",
    "df_target = df_target[df_target[\"cluster_label\"].notna()].copy()\n",
    "\n",
    "print(f\"Classification data: {df_target['embryo_id'].nunique()} embryos\")\n",
    "print(f\"Clusters: {df_target.groupby('cluster_label')['embryo_id'].nunique().to_dict()}\")\n",
    "\n",
    "FEATURE_SETS = {\n",
    "    \"curvature\": [\"baseline_deviation_normalized\"],\n",
    "    \"length\": [\"total_length_um\"],\n",
    "    \"embedding\": \"z_mu_b\",\n",
    "}\n",
    "FEATURE_LABELS = {\n",
    "    \"curvature\": \"Curvature\",\n",
    "    \"length\": \"Body Length\",\n",
    "    \"embedding\": \"VAE Embedding\",\n",
    "}\n",
    "CLUSTER_COLORS = {\n",
    "    \"Not Penetrant\": \"#4477AA\",\n",
    "    \"Low_to_High\": \"#EE6677\",\n",
    "    \"Intermediate\": \"#228833\",\n",
    "    \"High_to_Low\": \"#CCBB44\",\n",
    "}\n",
    "\n",
    "# --- Mode 1: One-vs-Rest ---\n",
    "print(\"\\nMode 1: One-vs-Rest classification\")\n",
    "ovr_results = {}\n",
    "for feat_key, features in FEATURE_SETS.items():\n",
    "    res = run_classification_test(\n",
    "        df_target, groupby=\"cluster_label\", groups=\"all\", reference=\"rest\",\n",
    "        features=features, n_permutations=50, n_jobs=4, verbose=False,\n",
    "    )\n",
    "    ovr_results[feat_key] = res\n",
    "\n",
    "fig = plot_feature_comparison_grid(\n",
    "    results_by_feature=ovr_results, feature_labels=FEATURE_LABELS,\n",
    "    cluster_colors=CLUSTER_COLORS, title=\"One-vs-Rest Classification by Feature Type\",\n",
    "    save_path=FIGURES_DIR / \"notebook_05_ovr_comparison.png\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# --- Mode 2: Each cluster vs Not Penetrant ---\n",
    "print(\"Mode 2: Each cluster vs Not Penetrant\")\n",
    "non_wt = [c for c in df_target[\"cluster_label\"].unique() if c != \"Not Penetrant\"]\n",
    "vs_wt_results = {}\n",
    "for feat_key, features in FEATURE_SETS.items():\n",
    "    res = run_classification_test(\n",
    "        df_target, groupby=\"cluster_label\", groups=non_wt,\n",
    "        reference=\"Not Penetrant\", features=features,\n",
    "        n_permutations=50, n_jobs=4, verbose=False,\n",
    "    )\n",
    "    vs_wt_results[feat_key] = res\n",
    "\n",
    "fig = plot_feature_comparison_grid(\n",
    "    results_by_feature=vs_wt_results, feature_labels=FEATURE_LABELS,\n",
    "    cluster_colors=CLUSTER_COLORS, title=\"Cluster vs Not Penetrant by Feature Type\",\n",
    "    save_path=FIGURES_DIR / \"notebook_05_vs_wt_comparison.png\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"Modes 1 & 2 done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Experiment Control Comparisons (Modes 3 & 4)\n",
    "\n",
    "These controls combine data from different experiments to test whether the classification framework correctly returns null results when groups **should** be indistinguishable:\n",
    "\n",
    "- **Mode 3 (negative control)**: Crispant vs homozygous mutant embryos that both fall in the Low_to_High cluster. If clustering captures genotype-independent morphology, AUROC should be ~0.5.\n",
    "- **Mode 4 (negative control)**: ab wildtype controls vs cep290_wildtype from the reference dataset. Two wildtype strains should be indistinguishable.\n",
    "\n",
    "**Important**: Because these comparisons span experiments, VAE embedding features are confounded by batch effects (expect inflated AUROCs ~0.8 for embedding even in null comparisons). Curvature and length are batch-robust and provide the true control signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Mode 3: Negative control — crispant vs homozygous within Low_to_High ---\n",
    "print(\"Mode 3: Crispant vs Homozygous Mutant (Low_to_High) — Negative Control\")\n",
    "\n",
    "# Load reference data (homozygous mutants with cluster labels)\n",
    "REFERENCE_CSV = CEP290_REF_DIR / \"embryo_data_with_labels.csv\"\n",
    "df_ref_full = pd.read_csv(REFERENCE_CSV, low_memory=False)\n",
    "df_ref_full = df_ref_full[df_ref_full[\"use_embryo_flag\"]].copy()\n",
    "\n",
    "# Filter to homozygous Low_to_High\n",
    "df_ref_lth = df_ref_full[\n",
    "    (df_ref_full[\"genotype\"] == \"cep290_homozygous\")\n",
    "    & (df_ref_full[\"cluster_categories\"] == \"Low_to_High\")\n",
    "].copy()\n",
    "\n",
    "# Filter target to crispant Low_to_High\n",
    "df_target_lth = df_target[\n",
    "    (df_target[\"genotype\"] == \"cep290_crispant\")\n",
    "    & (df_target[\"cluster_label\"] == \"Low_to_High\")\n",
    "].copy()\n",
    "\n",
    "print(f\"  Reference homozygous L2H: {df_ref_lth['embryo_id'].nunique()} embryos\")\n",
    "print(f\"  Target crispant L2H: {df_target_lth['embryo_id'].nunique()} embryos\")\n",
    "\n",
    "# Combine — assign a common column for comparison\n",
    "df_ref_lth = df_ref_lth.assign(comparison_group=\"cep290_homozygous\")\n",
    "df_target_lth = df_target_lth.assign(comparison_group=\"cep290_crispant\")\n",
    "\n",
    "shared_cols = sorted(set(df_ref_lth.columns) & set(df_target_lth.columns))\n",
    "df_neg_ctrl = pd.concat(\n",
    "    [df_ref_lth[shared_cols], df_target_lth[shared_cols]], ignore_index=True\n",
    ")\n",
    "\n",
    "neg_ctrl_results = {}\n",
    "for feat_key, features in FEATURE_SETS.items():\n",
    "    res = run_classification_test(\n",
    "        df_neg_ctrl,\n",
    "        groupby=\"comparison_group\",\n",
    "        groups=\"cep290_crispant\",\n",
    "        reference=\"cep290_homozygous\",\n",
    "        features=features,\n",
    "        n_permutations=50,  # Production: use 200+\n",
    "        n_jobs=4,\n",
    "        verbose=False,\n",
    "    )\n",
    "    neg_ctrl_results[feat_key] = res\n",
    "\n",
    "# --- Mode 4: Negative control — ab vs cep290_wildtype ---\n",
    "print(\"\\nMode 4: ab vs cep290_wildtype — Negative Control\")\n",
    "\n",
    "df_ref_wt = df_ref_full[df_ref_full[\"genotype\"] == \"cep290_wildtype\"].copy()\n",
    "df_target_ab = df_target[df_target[\"genotype\"] == \"ab\"].copy()\n",
    "\n",
    "df_ref_wt = df_ref_wt.assign(comparison_group=\"cep290_wildtype\")\n",
    "df_target_ab = df_target_ab.assign(comparison_group=\"ab\")\n",
    "\n",
    "print(f\"  Reference wildtype: {df_ref_wt['embryo_id'].nunique()} embryos\")\n",
    "print(f\"  Target ab: {df_target_ab['embryo_id'].nunique()} embryos\")\n",
    "\n",
    "shared_cols_pc = sorted(set(df_ref_wt.columns) & set(df_target_ab.columns))\n",
    "df_pos_ctrl = pd.concat(\n",
    "    [df_ref_wt[shared_cols_pc], df_target_ab[shared_cols_pc]], ignore_index=True\n",
    ")\n",
    "\n",
    "pos_ctrl_results = {}\n",
    "for feat_key, features in FEATURE_SETS.items():\n",
    "    res = run_classification_test(\n",
    "        df_pos_ctrl,\n",
    "        groupby=\"comparison_group\",\n",
    "        groups=\"ab\",\n",
    "        reference=\"cep290_wildtype\",\n",
    "        features=features,\n",
    "        n_permutations=50,  # Production: use 200+\n",
    "        n_jobs=4,\n",
    "        verbose=False,\n",
    "    )\n",
    "    pos_ctrl_results[feat_key] = res\n",
    "\n",
    "# Plot control comparisons side by side using plot_multiple_aurocs\n",
    "CTRL_COLORS = {\n",
    "    \"Crispant vs Homozygous (L2H)\": \"#EE6677\",\n",
    "    \"ab vs Wildtype (all)\": \"#4477AA\",\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, len(FEATURE_SETS), figsize=(6 * len(FEATURE_SETS), 5))\n",
    "for idx, feat_key in enumerate(FEATURE_SETS):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    dfs_dict = {}\n",
    "    # Negative control\n",
    "    neg_res = neg_ctrl_results[feat_key]\n",
    "    for (pos, neg), sub_df in neg_res.items():\n",
    "        dfs_dict[\"Crispant vs Homozygous (L2H)\"] = sub_df\n",
    "\n",
    "    # Positive control\n",
    "    pos_res = pos_ctrl_results[feat_key]\n",
    "    for (pos, neg), sub_df in pos_res.items():\n",
    "        dfs_dict[\"ab vs Wildtype (all)\"] = sub_df\n",
    "\n",
    "    plot_multiple_aurocs(\n",
    "        auroc_dfs_dict=dfs_dict,\n",
    "        colors_dict=CTRL_COLORS,\n",
    "        title=FEATURE_LABELS[feat_key],\n",
    "        ax=ax,\n",
    "        ylim=(0.3, 1.05),\n",
    "    )\n",
    "\n",
    "fig.suptitle(\n",
    "    \"Control Comparisons (expect AUROC \\u2248 0.5)\",\n",
    "    fontsize=16, fontweight=\"bold\", y=1.02,\n",
    ")\n",
    "fig.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"notebook_05_control_comparisons.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Modes 3 & 4 done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Summary\n",
    "\n",
    "Combined summary table across all four modes and three feature types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined summary table across all 4 modes\n",
    "summary_rows = []\n",
    "for mode, results_dict, mode_label in [\n",
    "    (\"ovr\", ovr_results, \"One-vs-Rest\"),\n",
    "    (\"vs_wt\", vs_wt_results, \"vs Not Penetrant\"),\n",
    "    (\"neg_ctrl\", neg_ctrl_results, \"Crispant vs Homozygous (L2H)\"),\n",
    "    (\"pos_ctrl\", pos_ctrl_results, \"ab vs Wildtype\"),\n",
    "]:\n",
    "    for feat_key, res in results_dict.items():\n",
    "        s = res.summary()\n",
    "        for _, row in s.iterrows():\n",
    "            summary_rows.append({\n",
    "                \"mode\": mode_label,\n",
    "                \"feature\": FEATURE_LABELS.get(feat_key, feat_key),\n",
    "                \"positive\": row[\"positive\"],\n",
    "                \"negative\": row[\"negative\"],\n",
    "                \"max_auroc\": row.get(\"max_auroc\", np.nan),\n",
    "                \"min_pval\": row.get(\"min_pval\", np.nan),\n",
    "            })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.to_csv(RESULTS_DIR / \"notebook_classification_summary.csv\", index=False)\n",
    "print(\"Classification summary saved\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Phenotype emergence**: CEP290 crispant penetrance becomes detectable ~26-30 hpf, consistent with homozygous mutant timing.\n",
    "2. **Embedding vs single metrics**: VAE embedding (z_mu_b) outperforms curvature or length alone for early phenotype detection (higher AUROC).\n",
    "3. **Cross-experiment controls**: Embedding-based controls (Modes 3/4) show inflated AUROCs (~0.8) even for expected-null comparisons due to VAE batch effects across experiments. Curvature and length controls correctly return ~0.5, confirming they are batch-robust.\n",
    "4. **Projection**: Bootstrap projection onto well-characterized reference clusters provides per-embryo confidence scores (max_p, entropy).\n",
    "5. **Practical implication**: For cross-experiment comparisons, prefer curvature-based metrics over embedding features. Use embedding features only within a single experiment or after batch correction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation_grounded_sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
