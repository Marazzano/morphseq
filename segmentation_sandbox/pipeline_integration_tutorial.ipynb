{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Integration Tutorial for Developers\n",
    "\n",
    "This tutorial covers advanced usage of the embryo metadata annotation system for pipeline developers and bioinformaticians.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "- **EmbryoMetadata**: Main class for persistent annotation storage\n",
    "- **AnnotationBatch**: Temporary workspace for batch operations\n",
    "- **Pipeline Script**: `07_embryo_metadata_update.py` for automated processing\n",
    "- **BaseFileHandler**: Atomic file operations with backup/recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Script Integration\n",
    "\n",
    "The `07_embryo_metadata_update.py` script integrates with your existing pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using the pipeline script\n",
    "import subprocess\n",
    "\n",
    "# Initialize metadata from SAM2\n",
    "result = subprocess.run([\n",
    "    'python', 'scripts/pipelines/07_embryo_metadata_update.py',\n",
    "    'path/to/sam2_annotations.json',\n",
    "    '--output-dir', 'data/'\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "print(\"Script output:\")\n",
    "print(result.stdout)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úÖ Metadata initialization successful\")\n",
    "else:\n",
    "    print(f\"‚ùå Script failed: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced API Usage\n",
    "\n",
    "### Direct Snip Manipulation\n",
    "\n",
    "For precise control, use the snip ID approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('scripts')\n",
    "\n",
    "from annotations.embryo_metadata import EmbryoMetadata\n",
    "from annotations.annotation_batch import AnnotationBatch\n",
    "\n",
    "# Load metadata\n",
    "metadata = EmbryoMetadata('path/to/your_sam2_file.json')\n",
    "\n",
    "# Direct snip ID manipulation for precise control\n",
    "specific_snips = [\n",
    "    \"20240418_A01_e01_s0100\",\n",
    "    \"20240418_A01_e01_s0150\", \n",
    "    \"20240418_A01_e02_s0200\"\n",
    "]\n",
    "\n",
    "result = metadata.add_phenotype(\n",
    "    phenotype=\"BLUR\",\n",
    "    author=\"pipeline_script\",\n",
    "    snip_ids=specific_snips\n",
    ")\n",
    "\n",
    "print(f\"Applied BLUR to {result['count']} specific snips\")\n",
    "print(f\"Approach: {result['approach']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing Workflow\n",
    "\n",
    "Use AnnotationBatch for safe, isolated operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batch workspace\n",
    "batch = metadata.initialize_batch(\n",
    "    mode=\"skeleton\",  # Empty annotations, preserve structure\n",
    "    author=\"automated_pipeline\"\n",
    ")\n",
    "\n",
    "print(f\"Created batch with {len(batch.data['embryos'])} embryos\")\n",
    "print(f\"Batch author: {batch.author}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add annotations to batch (isolated from main data)\n",
    "embryo_ids = list(batch.data[\"embryos\"].keys())[:5]  # First 5 embryos\n",
    "\n",
    "for i, embryo_id in enumerate(embryo_ids):\n",
    "    # Batch operations inherit author automatically\n",
    "    batch.add_phenotype(\"NORMAL\", embryo_id=embryo_id, target=\"all\")\n",
    "    \n",
    "    # Add genotypes based on experimental design\n",
    "    if i % 2 == 0:\n",
    "        batch.add_genotype(\"tmem67\", embryo_id=embryo_id, zygosity=\"homozygous\")\n",
    "    else:\n",
    "        batch.add_genotype(\"WT\", embryo_id=embryo_id, zygosity=\"homozygous\")\n",
    "\n",
    "print(f\"Added annotations to {len(embryo_ids)} embryos in batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview batch contents\n",
    "print(batch.preview(limit=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply batch with conflict resolution\n",
    "report = metadata.apply_batch(\n",
    "    batch,\n",
    "    on_conflict=\"merge\",  # Intelligently combine annotations\n",
    "    dry_run=True  # Test first\n",
    ")\n",
    "\n",
    "print(f\"Dry run results:\")\n",
    "print(f\"Would apply: {report['applied_count']} annotations\")\n",
    "print(f\"Would skip: {report['skipped_count']} conflicts\")\n",
    "print(f\"Errors: {len(report['errors'])}\")\n",
    "\n",
    "if len(report['errors']) == 0:\n",
    "    # Actually apply if no errors\n",
    "    final_report = metadata.apply_batch(batch, on_conflict=\"merge\")\n",
    "    print(f\"‚úÖ Applied {final_report['applied_count']} annotations\")\n",
    "else:\n",
    "    print(f\"‚ùå Errors found: {report['errors']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Multiple SAM2 Files\n",
    "\n",
    "Batch processing workflow for large datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Process multiple SAM2 files\n",
    "sam2_files = glob.glob(\"data/sam2_annotations/*.json\")\n",
    "output_dir = Path(\"data/embryo_metadata\")\n",
    "\n",
    "def process_sam2_file(sam2_path, output_dir):\n",
    "    \"\"\"Process a single SAM2 file.\"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Initialize metadata\n",
    "        metadata = EmbryoMetadata(str(sam2_path))\n",
    "        \n",
    "        # Generate output path\n",
    "        output_path = output_dir / f\"{Path(sam2_path).stem}_biology.json\"\n",
    "        \n",
    "        # Save with custom path\n",
    "        metadata.annotations_path = output_path\n",
    "        metadata.file_handler.file_path = output_path\n",
    "        metadata.save()\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        stats = metadata.get_stats()\n",
    "        \n",
    "        return {\n",
    "            \"file\": sam2_path,\n",
    "            \"embryos\": stats[\"embryo_count\"],\n",
    "            \"snips\": stats[\"total_snips\"],\n",
    "            \"time\": processing_time,\n",
    "            \"output\": output_path,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"file\": sam2_path,\n",
    "            \"error\": str(e),\n",
    "            \"status\": \"failed\"\n",
    "        }\n",
    "\n",
    "# Process files\n",
    "results = []\n",
    "for sam2_file in sam2_files[:3]:  # Process first 3 files\n",
    "    result = process_sam2_file(sam2_file, output_dir)\n",
    "    results.append(result)\n",
    "    \n",
    "    if result[\"status\"] == \"success\":\n",
    "        print(f\"‚úÖ {Path(result['file']).name}: {result['embryos']} embryos, {result['time']:.2f}s\")\n",
    "    else:\n",
    "        print(f\"‚ùå {Path(result['file']).name}: {result['error']}\")\n",
    "\n",
    "# Summary\n",
    "successful = [r for r in results if r[\"status\"] == \"success\"]\n",
    "total_embryos = sum(r[\"embryos\"] for r in successful)\n",
    "total_time = sum(r[\"time\"] for r in successful)\n",
    "\n",
    "print(f\"\\nSummary: {len(successful)}/{len(results)} files processed\")\n",
    "print(f\"Total embryos: {total_embryos}\")\n",
    "print(f\"Total time: {total_time:.2f}s\")\n",
    "print(f\"Average: {total_time/len(successful):.2f}s per file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Recovery and Validation\n",
    "\n",
    "Robust error handling for production pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_annotation_pipeline(sam2_path, annotation_plan):\n",
    "    \"\"\"\n",
    "    Robust annotation pipeline with error recovery.\n",
    "    \n",
    "    Args:\n",
    "        sam2_path: Path to SAM2 file\n",
    "        annotation_plan: Dict with annotation instructions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize with validation\n",
    "        metadata = EmbryoMetadata(sam2_path)\n",
    "        \n",
    "        # Create batch for safety\n",
    "        batch = metadata.initialize_batch(mode=\"skeleton\", author=\"pipeline\")\n",
    "        \n",
    "        errors = []\n",
    "        success_count = 0\n",
    "        \n",
    "        # Process annotation plan\n",
    "        for operation in annotation_plan:\n",
    "            try:\n",
    "                if operation[\"type\"] == \"phenotype\":\n",
    "                    result = batch.add_phenotype(\n",
    "                        phenotype=operation[\"phenotype\"],\n",
    "                        embryo_id=operation[\"embryo_id\"],\n",
    "                        target=operation.get(\"target\", \"all\"),\n",
    "                        overwrite_dead=operation.get(\"overwrite_dead\", False)\n",
    "                    )\n",
    "                    success_count += result[\"count\"]\n",
    "                    \n",
    "                elif operation[\"type\"] == \"genotype\":\n",
    "                    batch.add_genotype(\n",
    "                        gene=operation[\"gene\"],\n",
    "                        embryo_id=operation[\"embryo_id\"],\n",
    "                        zygosity=operation.get(\"zygosity\", \"unknown\"),\n",
    "                        overwrite=operation.get(\"overwrite\", False)\n",
    "                    )\n",
    "                    success_count += 1\n",
    "                    \n",
    "            except ValueError as e:\n",
    "                errors.append({\n",
    "                    \"operation\": operation,\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "                continue\n",
    "        \n",
    "        # Apply batch if no critical errors\n",
    "        if len(errors) < len(annotation_plan) * 0.5:  # Less than 50% errors\n",
    "            apply_report = metadata.apply_batch(batch, on_conflict=\"merge\")\n",
    "            metadata.save()\n",
    "            \n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"applied\": apply_report[\"applied_count\"],\n",
    "                \"errors\": errors,\n",
    "                \"error_rate\": len(errors) / len(annotation_plan)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"status\": \"failed\",\n",
    "                \"reason\": \"Too many errors\",\n",
    "                \"errors\": errors,\n",
    "                \"error_rate\": len(errors) / len(annotation_plan)\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"critical_failure\",\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# Example annotation plan\n",
    "annotation_plan = [\n",
    "    {\n",
    "        \"type\": \"phenotype\",\n",
    "        \"phenotype\": \"NORMAL\",\n",
    "        \"embryo_id\": \"20240418_A01_e01\",\n",
    "        \"target\": \"all\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"genotype\",\n",
    "        \"gene\": \"tmem67\",\n",
    "        \"embryo_id\": \"20240418_A01_e01\",\n",
    "        \"zygosity\": \"homozygous\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"phenotype\",\n",
    "        \"phenotype\": \"DEAD\",\n",
    "        \"embryo_id\": \"20240418_A01_e01\",\n",
    "        \"target\": \"200\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run pipeline\n",
    "result = robust_annotation_pipeline(\"path/to/sam2.json\", annotation_plan)\n",
    "print(f\"Pipeline result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Optimization\n",
    "\n",
    "Tips for optimal performance with large datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_annotation_methods(metadata, embryo_ids):\n",
    "    \"\"\"Compare performance of different annotation approaches.\"\"\"\n",
    "    \n",
    "    # Method 1: Individual operations\n",
    "    start_time = time.time()\n",
    "    for embryo_id in embryo_ids[:10]:\n",
    "        metadata.add_phenotype(\"NORMAL\", \"benchmark\", embryo_id, \"all\")\n",
    "    individual_time = time.time() - start_time\n",
    "    \n",
    "    # Method 2: Batch operations\n",
    "    start_time = time.time()\n",
    "    batch = metadata.initialize_batch(mode=\"skeleton\", author=\"benchmark\")\n",
    "    for embryo_id in embryo_ids[10:20]:\n",
    "        batch.add_phenotype(\"NORMAL\", embryo_id=embryo_id, target=\"all\")\n",
    "    metadata.apply_batch(batch)\n",
    "    batch_time = time.time() - start_time\n",
    "    \n",
    "    # Method 3: Direct snip operations (when precise control needed)\n",
    "    start_time = time.time()\n",
    "    # Collect all snip IDs for efficient batch operation\n",
    "    all_snips = []\n",
    "    for embryo_id in embryo_ids[20:30]:\n",
    "        embryo_snips = list(metadata.data[\"embryos\"][embryo_id][\"snips\"].keys())\n",
    "        all_snips.extend(embryo_snips[:5])  # First 5 snips per embryo\n",
    "    \n",
    "    metadata.add_phenotype(\"NORMAL\", \"benchmark\", snip_ids=all_snips)\n",
    "    direct_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Performance comparison (10 embryos):\")\n",
    "    print(f\"Individual operations: {individual_time:.3f}s\")\n",
    "    print(f\"Batch operations: {batch_time:.3f}s\")\n",
    "    print(f\"Direct snip operations: {direct_time:.3f}s\")\n",
    "    print(f\"\\nRecommendation: Use batch operations for safety and reasonable performance\")\n",
    "\n",
    "# Run benchmark if you have metadata loaded\n",
    "# benchmark_annotation_methods(metadata, metadata.list_embryos())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with Analysis Pipelines\n",
    "\n",
    "Export annotations for downstream analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def export_annotations_for_analysis(metadata, output_path):\n",
    "    \"\"\"Export annotations in analysis-ready format.\"\"\"\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    for embryo_id, embryo_data in metadata.data[\"embryos\"].items():\n",
    "        # Extract embryo-level info\n",
    "        genotype_info = embryo_data.get(\"genotype\", {})\n",
    "        \n",
    "        # Extract frame-level info\n",
    "        for snip_id, snip_data in embryo_data.get(\"snips\", {}).items():\n",
    "            frame_number = snip_data.get(\"frame_number\")\n",
    "            \n",
    "            # Create record for each phenotype\n",
    "            phenotypes = snip_data.get(\"phenotypes\", [])\n",
    "            if not phenotypes:\n",
    "                # Add record even if no phenotypes\n",
    "                records.append({\n",
    "                    \"embryo_id\": embryo_id,\n",
    "                    \"experiment_id\": embryo_data.get(\"experiment_id\"),\n",
    "                    \"video_id\": embryo_data.get(\"video_id\"),\n",
    "                    \"snip_id\": snip_id,\n",
    "                    \"frame_number\": frame_number,\n",
    "                    \"phenotype\": None,\n",
    "                    \"phenotype_author\": None,\n",
    "                    \"gene\": genotype_info.get(\"gene\"),\n",
    "                    \"zygosity\": genotype_info.get(\"zygosity\"),\n",
    "                    \"genotype_author\": genotype_info.get(\"author\")\n",
    "                })\n",
    "            else:\n",
    "                for phenotype in phenotypes:\n",
    "                    records.append({\n",
    "                        \"embryo_id\": embryo_id,\n",
    "                        \"experiment_id\": embryo_data.get(\"experiment_id\"),\n",
    "                        \"video_id\": embryo_data.get(\"video_id\"),\n",
    "                        \"snip_id\": snip_id,\n",
    "                        \"frame_number\": frame_number,\n",
    "                        \"phenotype\": phenotype[\"value\"],\n",
    "                        \"phenotype_author\": phenotype[\"author\"],\n",
    "                        \"gene\": genotype_info.get(\"gene\"),\n",
    "                        \"zygosity\": genotype_info.get(\"zygosity\"),\n",
    "                        \"genotype_author\": genotype_info.get(\"author\")\n",
    "                    })\n",
    "    \n",
    "    # Create DataFrame and save\n",
    "    df = pd.DataFrame(records)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Exported {len(records)} annotation records to {output_path}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example export\n",
    "# df = export_annotations_for_analysis(metadata, \"analysis_data.csv\")\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Conflict Resolution\n",
    "\n",
    "Handle complex merge scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_batch_merge(metadata, batch1, batch2):\n",
    "    \"\"\"Merge multiple batches with custom conflict resolution.\"\"\"\n",
    "    \n",
    "    # Apply first batch\n",
    "    report1 = metadata.apply_batch(batch1, on_conflict=\"merge\", dry_run=True)\n",
    "    print(f\"Batch 1 dry run: {report1['applied_count']} would be applied\")\n",
    "    \n",
    "    if len(report1['errors']) == 0:\n",
    "        metadata.apply_batch(batch1, on_conflict=\"merge\")\n",
    "        print(\"‚úÖ Batch 1 applied successfully\")\n",
    "    \n",
    "    # Apply second batch with different strategy\n",
    "    report2 = metadata.apply_batch(batch2, on_conflict=\"skip\", dry_run=True)\n",
    "    print(f\"Batch 2 dry run: {report2['applied_count']} would be applied, {report2['skipped_count']} skipped\")\n",
    "    \n",
    "    if report2['applied_count'] > 0:\n",
    "        metadata.apply_batch(batch2, on_conflict=\"skip\")\n",
    "        print(\"‚úÖ Batch 2 applied with conflict skipping\")\n",
    "    \n",
    "    return {\n",
    "        \"batch1_applied\": report1['applied_count'],\n",
    "        \"batch2_applied\": report2['applied_count'],\n",
    "        \"batch2_skipped\": report2['skipped_count']\n",
    "    }\n",
    "\n",
    "# Example usage with simulated batches\n",
    "# result = advanced_batch_merge(metadata, batch1, batch2)\n",
    "# print(f\"Merge result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring and Logging\n",
    "\n",
    "Production-ready logging and monitoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('annotation_pipeline.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def monitored_annotation_pipeline(sam2_files, output_dir):\n",
    "    \"\"\"Annotation pipeline with comprehensive monitoring.\"\"\"\n",
    "    \n",
    "    logger.info(f\"Starting annotation pipeline for {len(sam2_files)} files\")\n",
    "    \n",
    "    stats = {\n",
    "        \"files_processed\": 0,\n",
    "        \"files_failed\": 0,\n",
    "        \"total_embryos\": 0,\n",
    "        \"total_annotations\": 0,\n",
    "        \"start_time\": datetime.now()\n",
    "    }\n",
    "    \n",
    "    for sam2_file in sam2_files:\n",
    "        try:\n",
    "            logger.info(f\"Processing {sam2_file}\")\n",
    "            \n",
    "            # Process file\n",
    "            metadata = EmbryoMetadata(sam2_file)\n",
    "            file_stats = metadata.get_stats()\n",
    "            \n",
    "            # Update statistics\n",
    "            stats[\"files_processed\"] += 1\n",
    "            stats[\"total_embryos\"] += file_stats[\"embryo_count\"]\n",
    "            stats[\"total_annotations\"] += file_stats[\"total_phenotypes\"]\n",
    "            \n",
    "            # Save with monitoring\n",
    "            output_path = output_dir / f\"{Path(sam2_file).stem}_biology.json\"\n",
    "            metadata.annotations_path = output_path\n",
    "            metadata.file_handler.file_path = output_path\n",
    "            metadata.save()\n",
    "            \n",
    "            logger.info(f\"Completed {sam2_file}: {file_stats['embryo_count']} embryos\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            stats[\"files_failed\"] += 1\n",
    "            logger.error(f\"Failed to process {sam2_file}: {str(e)}\")\n",
    "    \n",
    "    # Final statistics\n",
    "    stats[\"end_time\"] = datetime.now()\n",
    "    stats[\"duration\"] = (stats[\"end_time\"] - stats[\"start_time\"]).total_seconds()\n",
    "    \n",
    "    logger.info(f\"Pipeline completed:\")\n",
    "    logger.info(f\"  Files processed: {stats['files_processed']}/{len(sam2_files)}\")\n",
    "    logger.info(f\"  Total embryos: {stats['total_embryos']}\")\n",
    "    logger.info(f\"  Duration: {stats['duration']:.1f}s\")\n",
    "    logger.info(f\"  Rate: {stats['files_processed']/stats['duration']:.2f} files/s\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Example usage\n",
    "# sam2_files = glob.glob(\"data/sam2_annotations/*.json\")\n",
    "# output_dir = Path(\"data/embryo_metadata\")\n",
    "# stats = monitored_annotation_pipeline(sam2_files, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices Summary\n",
    "\n",
    "### For Pipeline Integration:\n",
    "\n",
    "1. **Use batch operations** for safety and isolation\n",
    "2. **Implement dry-run validation** before applying changes\n",
    "3. **Handle errors gracefully** with appropriate recovery\n",
    "4. **Use appropriate conflict resolution** strategies\n",
    "5. **Monitor performance** and log operations\n",
    "6. **Export data** in analysis-ready formats\n",
    "\n",
    "### Performance Guidelines:\n",
    "\n",
    "- **Batch operations**: ~100-1000 embryos per batch for optimal performance\n",
    "- **File operations**: Use atomic saves to prevent corruption\n",
    "- **Memory usage**: Monitor with large datasets (>10k embryos)\n",
    "- **Parallelization**: Process independent SAM2 files in parallel\n",
    "\n",
    "### Error Handling:\n",
    "\n",
    "- **Validate inputs** before batch operations\n",
    "- **Use dry-run mode** for complex operations\n",
    "- **Implement retries** for transient failures\n",
    "- **Log all operations** for debugging\n",
    "- **Monitor error rates** and alert on anomalies\n",
    "\n",
    "This system is designed to be robust, performant, and integrate seamlessly with your existing bioinformatics pipelines. üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}