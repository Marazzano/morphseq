# Module 4: QC Integration & GSAM Refactoring (Complete)

## Overview
Refactor existing `GSAMQualityControl` class into Module 4 architecture while preserving all performance optimizations and functionality. Create unified QC system with strict separation between **image integrity QC** and **embryo integrity QC**.

## Architecture Transformation

### Current State (Working)
```
gsam_qc_class.py
â””â”€â”€ GSAMQualityControl (monolithic, but performant)
    â”œâ”€â”€ Entity tracking optimization
    â”œâ”€â”€ Progress reporting (tqdm)
    â”œâ”€â”€ 7 different QC checks
    â”œâ”€â”€ Direct GSAM JSON manipulation
    â””â”€â”€ Overview generation
```

### Target State (Module 4 Aligned)
```
utils/qc/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ qc_flags.py              # Extracted flag system + validation
â”œâ”€â”€ embryo_qc.py            # Refactored GSAMQualityControl â†’ EmbryoSegmentationQC
â””â”€â”€ image_qc.py             # New: ImageQualityAnalyzer
```

## Files to Create/Modify

### 1. Create `utils/qc/qc_flags.py`

```python
"""
Unified QC flag definitions and validation.
Extracted from hardcoded strings in original GSAMQualityControl.
"""

from typing import Dict, List, Optional
from datetime import datetime

# ========================================
# FLAG VOCABULARIES
# ========================================

IMAGE_INTEGRITY_FLAGS = {
    'BLUR': {
        'desc': 'Low focus/sharpness detected',
        'level': 'image',
        'auto_detectable': True
    },
    'DARK': {
        'desc': 'Underexposed image',
        'level': 'image', 
        'auto_detectable': True
    },
    'OVEREXPOSED': {
        'desc': 'Overexposed/blown out',
        'level': 'image',
        'auto_detectable': True
    },
    'CORRUPT': {
        'desc': 'File corrupted or unreadable',
        'level': 'image',
        'auto_detectable': True
    },
    'EMPTY': {
        'desc': 'Nearly blank image',
        'level': 'image',
        'auto_detectable': True
    },
    'FOCUS_DRIFT': {
        'desc': 'Focus quality degraded over time',
        'level': 'video',
        'auto_detectable': True
    }
}

EMBRYO_INTEGRITY_FLAGS = {
    # From existing GSAMQualityControl checks
    'HIGH_SEGMENTATION_VAR_SNIP': {
        'desc': 'High area variance for snip compared to nearby frames',
        'level': 'snip',
        'auto_detectable': True,
        'threshold': 0.20
    },
    'HIGH_SEGMENTATION_VAR_EMBRYO': {
        'desc': 'High area variance across entire embryo track (CV > 15%)',
        'level': 'embryo', 
        'auto_detectable': True,
        'threshold': 0.15
    },
    'MASK_ON_EDGE': {
        'desc': 'Mask within 5 pixels of image edge',
        'level': 'snip',
        'auto_detectable': True,
        'margin_pixels': 5
    },
    'DETECTION_FAILURE': {
        'desc': 'Expected embryos missing from image',
        'level': 'image',
        'auto_detectable': True
    },
    'BBOX_OVERLAP': {
        'desc': 'Bounding box overlap >20% between embryos',
        'level': 'image',
        'auto_detectable': True,
        'threshold': 0.2
    },
    'MASK_OVERLAP_ERROR': {
        'desc': 'Mask pixel overlap between embryos',
        'level': 'image', 
        'auto_detectable': True
    },
    'UNUSUALLY_LARGE_MASK': {
        'desc': 'Mask area >15% of total image area',
        'level': 'snip',
        'auto_detectable': True,
        'threshold_pct': 0.15
    },
    'DISCONTINUOUS_MASK': {
        'desc': 'Mask contains multiple disconnected components',
        'level': 'snip',
        'auto_detectable': True
    }
}

# Manual flags that can be added by human reviewers
MANUAL_FLAGS = {
    'MOTION_BLUR': {'desc': 'Motion blur detected manually', 'level': 'snip'},
    'POOR_SEGMENTATION': {'desc': 'Manual review: poor mask quality', 'level': 'snip'},
    'ARTIFACT': {'desc': 'Image contains artifacts', 'level': 'image'},
    'EXCLUDE': {'desc': 'Manually excluded from analysis', 'level': 'any'}
}

ALL_FLAGS = {**IMAGE_INTEGRITY_FLAGS, **EMBRYO_INTEGRITY_FLAGS, **MANUAL_FLAGS}

# ========================================
# VALIDATION & UTILITIES
# ========================================

def validate_flag(qc_type: str, flag: str) -> bool:
    """
    Validate that flag exists in appropriate vocabulary.
    
    Args:
        qc_type: 'image_integrity', 'embryo_integrity', or 'manual'
        flag: Flag name to validate
        
    Returns:
        True if valid
        
    Raises:
        ValueError: If flag not found in vocabulary
    """
    vocab_map = {
        'image_integrity': IMAGE_INTEGRITY_FLAGS,
        'embryo_integrity': EMBRYO_INTEGRITY_FLAGS, 
        'manual': MANUAL_FLAGS
    }
    
    if qc_type not in vocab_map:
        raise ValueError(f"Unknown QC type: {qc_type}")
        
    if flag not in vocab_map[qc_type]:
        available = list(vocab_map[qc_type].keys())
        raise ValueError(f"Unknown {qc_type} flag: {flag}. Available: {available}")
        
    return True

def get_flag_info(flag: str) -> Dict:
    """Get flag metadata."""
    return ALL_FLAGS.get(flag, {})

def create_flag_entry(flag: str, qc_type: str, author: str, **kwargs) -> Dict:
    """
    Create standardized flag entry with validation.
    
    Args:
        flag: Flag name
        qc_type: QC type for validation
        author: Who created the flag
        **kwargs: Additional flag-specific data
        
    Returns:
        Standardized flag dict
    """
    validate_flag(qc_type, flag)
    
    entry = {
        'flag': flag,
        'author': author,
        'timestamp': datetime.now().isoformat(),
        **kwargs
    }
    
    return entry

def get_flags_by_level(level: str) -> List[str]:
    """Get all flags that apply to a specific level (image, video, snip, embryo)."""
    return [flag for flag, info in ALL_FLAGS.items() if info.get('level') == level]
```

### 2. Create `utils/qc/image_qc.py`

```python
"""
Image Integrity QC: Automated image quality analysis.
NEW component - handles focus, exposure, corruption detection.
Independent of embryo/annotation data.
"""

import cv2
import numpy as np
from pathlib import Path
from typing import Dict, List, Union, Optional
from datetime import datetime
from .qc_flags import IMAGE_INTEGRITY_FLAGS, validate_flag, create_flag_entry

try:
    from tqdm import tqdm
    _HAS_TQDM = True
except ImportError:
    _HAS_TQDM = False

class ImageQualityAnalyzer:
    """
    Analyze raw image quality independent of annotations.
    Designed to run in Step 02 before any mask generation.
    """
    
    def __init__(self, thresholds: Optional[Dict] = None, verbose: bool = True):
        """
        Initialize with quality thresholds.
        
        Args:
            thresholds: Override default thresholds
            verbose: Enable progress output
        """
        self.thresholds = thresholds or {
            'blur_min': 100.0,           # Laplacian variance threshold
            'dark_mean_max': 35.0,       # Max mean for DARK flag
            'bright_mean_min': 220.0,    # Min mean for OVEREXPOSED flag  
            'empty_variance_max': 5.0,   # Max variance for EMPTY flag
            'focus_drift_threshold': 0.3 # Relative drop for FOCUS_DRIFT
        }
        self.verbose = verbose
        
    # ========================================
    # SINGLE IMAGE ANALYSIS  
    # ========================================
    
    def analyze_image(self, image_path: Union[str, Path, np.ndarray]) -> Dict:
        """
        Analyze single image for quality issues.
        
        Args:
            image_path: Path to image or numpy array
            
        Returns:
            {
                'flags': ['BLUR', 'DARK', ...],
                'metrics': {'blur': 87.3, 'mean': 30.1, ...},
                'timestamp': '...'
            }
        """
        # Load image
        img = self._load_image(image_path)
        
        flags = []
        metrics = {}
        
        # Corruption check first
        if self._is_corrupt(img):
            flags.append('CORRUPT')
            return {
                'flags': flags,
                'metrics': {},
                'timestamp': datetime.now().isoformat()
            }
        
        # Focus/blur analysis
        blur_metric = self._compute_blur_metric(img)
        metrics['blur'] = blur_metric
        if blur_metric < self.thresholds['blur_min']:
            flags.append('BLUR')
            
        # Brightness analysis
        mean_brightness = self._compute_brightness(img)
        metrics['mean_brightness'] = mean_brightness
        if mean_brightness < self.thresholds['dark_mean_max']:
            flags.append('DARK')
        elif mean_brightness > self.thresholds['bright_mean_min']:
            flags.append('OVEREXPOSED')
            
        # Empty/blank detection
        variance = self._compute_variance(img)
        metrics['variance'] = variance
        if variance < self.thresholds['empty_variance_max']:
            flags.append('EMPTY')
            
        # Validate all flags
        for flag in flags:
            validate_flag('image_integrity', flag)
            
        return {
            'flags': flags,
            'metrics': metrics, 
            'timestamp': datetime.now().isoformat()
        }
    
    # ========================================
    # BATCH ANALYSIS
    # ========================================
    
    def analyze_batch(self, image_paths: List[Union[str, Path]], 
                     author: str = "image_qc_auto",
                     parallel: bool = False) -> Dict:
        """
        Analyze batch of images with progress tracking.
        
        Args:
            image_paths: List of image paths
            author: Author identifier
            parallel: Use threading (future enhancement)
            
        Returns:
            {
                'run_metadata': {...},
                'per_image': {path: analysis_result, ...},
                'summary': {flag: count, ...},
                'focus_drift_analysis': {...}
            }
        """
        if self.verbose:
            print(f"ðŸ” Analyzing {len(image_paths)} images for quality issues...")
            
        per_image = {}
        
        # Progress wrapper
        iterator = self._progress_iter(image_paths, desc="Image QC")
        
        for img_path in iterator:
            try:
                result = self.analyze_image(img_path)
                per_image[str(img_path)] = result
            except Exception as e:
                if self.verbose:
                    print(f"âš ï¸  Error analyzing {img_path}: {e}")
                per_image[str(img_path)] = {
                    'flags': ['CORRUPT'],
                    'metrics': {},
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
        
        # Generate summary
        summary = self._generate_summary(per_image)
        
        # Focus drift analysis (if images are sequential)
        focus_drift = self._analyze_focus_drift(per_image, image_paths)
        
        return {
            'run_metadata': {
                'timestamp': datetime.now().isoformat(),
                'author': author,
                'total_images': len(image_paths),
                'thresholds': self.thresholds
            },
            'per_image': per_image,
            'summary': summary,
            'focus_drift_analysis': focus_drift
        }
    
    # ========================================
    # HELPER METHODS
    # ========================================
    
    def _load_image(self, image_path: Union[str, Path, np.ndarray]) -> np.ndarray:
        """Load image from path or return array."""
        if isinstance(image_path, np.ndarray):
            return image_path
        return cv2.imread(str(image_path))
    
    def _is_corrupt(self, img: np.ndarray) -> bool:
        """Check if image is corrupt/unloadable."""
        return img is None or img.size == 0 or len(img.shape) != 3
    
    def _compute_blur_metric(self, img: np.ndarray) -> float:
        """Compute Laplacian variance as focus proxy."""
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        return float(cv2.Laplacian(gray, cv2.CV_64F).var())
    
    def _compute_brightness(self, img: np.ndarray) -> float:
        """Compute mean pixel intensity."""
        return float(np.mean(img))
    
    def _compute_variance(self, img: np.ndarray) -> float:
        """Compute image variance."""
        return float(np.var(img))
    
    def _progress_iter(self, iterable, desc: str):
        """Progress wrapper compatible with tqdm."""
        if _HAS_TQDM and self.verbose:
            return tqdm(iterable, desc=desc, leave=False)
        return iterable
    
    def _generate_summary(self, per_image: Dict) -> Dict:
        """Generate flag count summary."""
        summary = {}
        for analysis in per_image.values():
            for flag in analysis.get('flags', []):
                summary[flag] = summary.get(flag, 0) + 1
        return summary
    
    def _analyze_focus_drift(self, per_image: Dict, image_paths: List) -> Dict:
        """Analyze focus quality drift over sequence."""
        blur_values = []
        for path in image_paths:
            analysis = per_image.get(str(path), {})
            blur = analysis.get('metrics', {}).get('blur')
            if blur is not None:
                blur_values.append(blur)
        
        if len(blur_values) < 10:  # Need sufficient samples
            return {'insufficient_data': True}
        
        # Compare first 20% to last 20% 
        n = len(blur_values)
        start_median = np.median(blur_values[:n//5])
        end_median = np.median(blur_values[-n//5:])
        
        drift_ratio = (start_median - end_median) / start_median if start_median > 0 else 0
        has_drift = drift_ratio > self.thresholds['focus_drift_threshold']
        
        return {
            'has_focus_drift': has_drift,
            'drift_ratio': float(drift_ratio),
            'start_median_blur': float(start_median),
            'end_median_blur': float(end_median),
            'total_frames': len(blur_values)
        }
```

### 3. Refactor `utils/qc/embryo_qc.py`

```python
"""
Embryo Integrity QC: Refactored from GSAMQualityControl.
Preserves all performance optimizations while adding Module 4 structure.
"""

import numpy as np
import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set
from datetime import datetime
from collections import defaultdict
from time import time

try:
    from tqdm import tqdm
    _HAS_TQDM = True
except ImportError:
    _HAS_TQDM = False

from .qc_flags import EMBRYO_INTEGRITY_FLAGS, validate_flag, create_flag_entry

class EmbryoSegmentationQC:
    """
    Refactored GSAMQualityControl with Module 4 architecture.
    
    PRESERVED FROM ORIGINAL:
    - All performance optimizations (entity tracking)
    - Progress reporting (tqdm integration)  
    - All existing QC checks
    - Direct GSAM JSON manipulation
    - Overview generation
    
    ADDED FOR MODULE 4:
    - Structured flag validation
    - Cleaner separation of concerns
    - Better error handling
    - Enhanced documentation
    """
    
    def __init__(self, gsam_path: str, verbose: bool = True, progress: bool = True):
        """
        Initialize QC with path to GSAM annotations.
        
        Args:
            gsam_path: Path to grounded_sam_annotations.json
            verbose: Whether to print progress
            progress: Whether to show progress bars
        """
        self.gsam_path = Path(gsam_path)
        self.verbose = verbose
        self.progress = progress
        
        # Load GSAM data
        with open(self.gsam_path, 'r') as f:
            self.gsam_data = json.load(f)
            
        # Initialize tracking sets for processed entities (PRESERVED OPTIMIZATION)
        self._initialize_entity_tracking()
        
        if self.verbose:
            print(f"ðŸ” Loaded GSAM annotations from {self.gsam_path}")
            print(f"ðŸ“Š Found {len(self.processed_snip_ids)} already processed snips")
        
        if self.verbose and self.progress:
            if _HAS_TQDM:
                print("â³ Progress bars enabled (tqdm).")
            else:
                print("â³ tqdm not installed; using basic percentage progress.")
    
    # ========================================
    # ENTITY TRACKING (PRESERVED FROM ORIGINAL)
    # ========================================
    
    def _initialize_entity_tracking(self):
        """Simple and fast entity tracking using stored processed IDs."""
        
        if self.verbose:
            print("ðŸ”„ Initializing entity tracking...")
            start_time = time()
        
        # Get previously processed IDs from GSAM data (or empty sets if first run)
        qc_meta = self.gsam_data.setdefault("qc_meta", {})
        self.processed_experiment_ids = set(qc_meta.get("processed_experiment_ids", []))
        self.processed_video_ids = set(qc_meta.get("processed_video_ids", []))
        self.processed_image_ids = set(qc_meta.get("processed_image_ids", []))
        self.processed_snip_ids = set(qc_meta.get("processed_snip_ids", []))
        
        # Find all current entities in the data
        all_experiment_ids = set()
        all_video_ids = set()
        all_image_ids = set()
        all_snip_ids = set()
        
        experiments_items = list(self.gsam_data.get("experiments", {}).items())
        for exp_id, exp_data in self._progress_iter(experiments_items, desc="Scanning", total=len(experiments_items)):
            all_experiment_ids.add(exp_id)
            
            for video_id, video_data in exp_data.get("videos", {}).items():
                all_video_ids.add(video_id)
                
                for image_id, image_data in video_data.get("images", {}).items():
                    all_image_ids.add(image_id)
                    
                    for embryo_id, embryo_data in image_data.get("embryos", {}).items():
                        snip_id = embryo_data.get("snip_id")
                        if snip_id:
                            all_snip_ids.add(snip_id)
        
        # New entities = all entities - processed entities
        self.new_experiment_ids = all_experiment_ids - self.processed_experiment_ids
        self.new_video_ids = all_video_ids - self.processed_video_ids
        self.new_image_ids = all_image_ids - self.processed_image_ids
        self.new_snip_ids = all_snip_ids - self.processed_snip_ids
        
        if self.verbose:
            elapsed = time() - start_time
            print(f"ðŸ“Š Previously processed: {len(self.processed_snip_ids)} snips")
            print(f"ðŸ†• New to process: {len(self.new_snip_ids)} snips")
            print(f"â±ï¸  Initialization took: {elapsed:.2f}s")

    def _mark_entities_checked(self, entities):
        """Mark entities as processed by adding them to the stored sets."""
        ts = datetime.now().isoformat()
        
        # Update our tracking sets
        self.processed_experiment_ids.update(entities.get("experiment_ids", []))
        self.processed_video_ids.update(entities.get("video_ids", []))
        self.processed_image_ids.update(entities.get("image_ids", []))
        self.processed_snip_ids.update(entities.get("snip_ids", []))
        
        # Save to GSAM data for persistence
        qc_meta = self.gsam_data.setdefault("qc_meta", {})
        qc_meta["processed_experiment_ids"] = sorted(self.processed_experiment_ids)
        qc_meta["processed_video_ids"] = sorted(self.processed_video_ids)
        qc_meta["processed_image_ids"] = sorted(self.processed_image_ids)
        qc_meta["processed_snip_ids"] = sorted(self.processed_snip_ids)
        qc_meta["last_updated"] = ts

    # ========================================
    # PROGRESS REPORTING (PRESERVED FROM ORIGINAL)
    # ========================================
    
    def _progress_iter(self, iterable, desc: str, total: Optional[int] = None):
        """Wrap an iterable with a progress indicator compatible with tmux."""
        if not self.progress:
            for x in iterable:
                yield x
            return
        if _HAS_TQDM:
            yield from tqdm(iterable, desc=desc, total=total, leave=False)
        else:
            data = list(iterable) if total is None else list(iterable)
            if total is None:
                total = len(data)
            last_pct = -1
            for idx, x in enumerate(data, 1):
                pct = int(idx / total * 100)
                if pct != last_pct and (pct % 5 == 0 or pct >= 97):
                    print(f"{desc}: {pct}% ({idx}/{total})", end="\r")
                    last_pct = pct
                yield x
            print(f"{desc}: 100% ({total}/{total})")
    
    # ========================================
    # MAIN ORCHESTRATION (ENHANCED FROM ORIGINAL)
    # ========================================
    
    def run_all_checks(self, author: str = "auto_qc", process_all: bool = False, 
                      target_entities: Optional[Dict[str, List[str]]] = None,
                      config: Optional[Dict] = None):
        """
        Run all QC checks and save flags to GSAM file.
        
        Args:
            author: Author identifier for the QC run
            process_all: If True, process all entities. If False, only process new entities
            target_entities: Specific entities to process (overrides process_all)
            config: Configuration overrides for specific checks
        """
        start_overall = time()
        
        # Determine which entities to process
        if target_entities:
            entities_to_process = target_entities
        elif process_all:
            entities_to_process = {
                "experiment_ids": list(self.processed_experiment_ids | self.new_experiment_ids),
                "video_ids": list(self.processed_video_ids | self.new_video_ids),
                "image_ids": list(self.processed_image_ids | self.new_image_ids),
                "snip_ids": list(self.processed_snip_ids | self.new_snip_ids)
            }
        else:
            # Default: only process new entities
            entities_to_process = {
                "experiment_ids": list(self.new_experiment_ids),
                "video_ids": list(self.new_video_ids),
                "image_ids": list(self.new_image_ids),
                "snip_ids": list(self.new_snip_ids)
            }
        
        if self.verbose:
            print(f"ðŸš€ Running embryo QC checks on {len(entities_to_process['snip_ids'])} snips...")
            
        # Mark entities checked before running checks
        self._mark_entities_checked(entities_to_process)

        # Run all checks (PRESERVED FROM ORIGINAL, ENHANCED WITH VALIDATION)
        self.check_segmentation_variability(author, entities_to_process, config)
        self.check_mask_on_edge(author, entities_to_process, config)
        self.check_overlapping_masks(author, entities_to_process, config)
        self.check_large_masks(author, entities_to_process, config)
        self.check_detection_failure(author, entities_to_process, config)
        self.check_discontinuous_masks(author, entities_to_process, config)
        
        elapsed = time() - start_overall
        if self.verbose:
            print(f"â±ï¸  Total QC elapsed: {elapsed:.2f}s")
        
        # Generate overview and save
        self.generate_overview(entities_to_process)
        self._save_qc_summary(author)
        
        if self.verbose:
            print("âœ… Embryo QC checks complete and flags saved to GSAM file")
    
    # ========================================
    # QC CHECKS (PRESERVED FROM ORIGINAL + ENHANCED VALIDATION)
    # ========================================
   
    def check_segmentation_variability(self, author: str, entities: Dict[str, List[str]], 
                                     config: Optional[Dict] = None):
        """
        Flag embryos with high area variance across frames.
        PRESERVED: Original algorithm and performance optimizations
        ENHANCED: Flag validation and config support
        """
        if self.verbose:
            print("ðŸ“Š Checking segmentation variability...")
        
        # Config with defaults
        cfg = config or {}
        cv_threshold = cfg.get('cv_threshold', EMBRYO_INTEGRITY_FLAGS['HIGH_SEGMENTATION_VAR_EMBRYO']['threshold'])
        snip_threshold = cfg.get('snip_threshold', EMBRYO_INTEGRITY_FLAGS['HIGH_SEGMENTATION_VAR_SNIP']['threshold'])
        n_frames_check = cfg.get('n_frames_check', 2)
        
        target_snips = set(entities.get("snip_ids", []))
        t0 = time()
        
        experiments_items = list(self.gsam_data.get("experiments", {}).items())
        for exp_id, exp_data in self._progress_iter(experiments_items, desc="SegVar", total=len(experiments_items)):
            if exp_id not in entities.get("experiment_ids", []):
                continue

            for video_id, video_data in exp_data.get("videos", {}).items():
                if video_id not in entities.get("video_ids", []):
                    continue

                image_ids = sorted(video_data.get("images", {}).keys())
                embryo_frames = defaultdict(dict)  # embryo_id -> {image_id: area}
                embryo_areas = defaultdict(list)   # embryo_id -> [area, ...]

                # Collect areas (PRESERVED ALGORITHM)
                for image_id in image_ids:
                    image_data = video_data["images"][image_id]
                    for embryo_id, embryo_data in image_data.get("embryos", {}).items():
                        area = embryo_data.get("area")
                        if area is not None:
                            embryo_frames[embryo_id][image_id] = area
                            embryo_areas[embryo_id].append(area)

                # Embryo-level variability check (PRESERVED + ENHANCED VALIDATION)
                for embryo_id, areas in embryo_areas.items():
                    if len(areas) >= 3:
                        mean_area = np.mean(areas)
                        cv = np.std(areas) / mean_area if mean_area > 0 else 0
                        if cv > cv_threshold:
                            # Find representative embryo_data to attach flag
                            for image_id in image_ids:
                                image_data = video_data["images"][image_id]
                                if embryo_id in image_data.get("embryos", {}):
                                    embryo_data = image_data["embryos"][embryo_id]
                                    
                                    # ENHANCED: Use structured flag creation
                                    flag_data = create_flag_entry(
                                        'HIGH_SEGMENTATION_VAR_EMBRYO',
                                        'embryo_integrity', 
                                        author,
                                        experiment_id=exp_id,
                                        video_id=video_id,
                                        embryo_id=embryo_id,
                                        coefficient_of_variation=round(cv, 3),
                                        frame_count=len(areas),
                                        mean_area=round(mean_area, 1),
                                        std_area=round(np.std(areas), 1)
                                    )
                                    
                                    embryo_data.setdefault("flags", {}) \
                                               .setdefault("HIGH_SEGMENTATION_VAR_EMBRYO", []) \
                                               .append(flag_data)
                                    break

                # Snip-level variability check (PRESERVED ALGORITHM + ENHANCED VALIDATION)
                for i, image_id in enumerate(image_ids):
                    image_data = video_data["images"][image_id]
                    for embryo_id, embryo_data in image_data.get("embryos", {}).items():
                        snip_id = embryo_data.get("snip_id")
                        if not snip_id or snip_id not in target_snips:
                            continue

                        current_area = embryo_data.get("area")
                        if current_area is None:
                            continue

                        # Get areas from nearby frames (PRESERVED ALGORITHM)
                        before_areas = []
                        after_areas = []

                        for j in range(max(0, i - n_frames_check), i):
                            frame_id = image_ids[j]
                            if frame_id in embryo_frames[embryo_id]:
                                before_areas.append(embryo_frames[embryo_id][frame_id])

                        for j in range(i + 1, min(len(image_ids), i + n_frames_check + 1)):
                            frame_id = image_ids[j]
                            if frame_id in embryo_frames[embryo_id]:
                                after_areas.append(embryo_frames[embryo_id][frame_id])

                        avg_before = np.mean(before_areas) if before_areas else None
                        avg_after = np.mean(after_areas) if after_areas else None

                        diff_before_pct = abs(current_area - avg_before) / avg_before if avg_before else None
                        diff_after_pct = abs(current_area - avg_after) / avg_after if avg_after else None

                        flag_before = diff_before_pct > snip_threshold if diff_before_pct is not None else False
                        flag_after = diff_after_pct > snip_threshold if diff_after_pct is not None else False

                        if flag_before or flag_after:
                            # ENHANCED: Use structured flag creation
                            flag_data = create_flag_entry(
                                'HIGH_SEGMENTATION_VAR_SNIP',
                                'embryo_integrity',
                                author,
                                snip_id=snip_id,
                                current_area=round(current_area, 1),
                                avg_before=round(avg_before, 1) if avg_before else None,
                                avg_after=round(avg_after, 1) if avg_after else None,
                                diff_before_pct=round(diff_before_pct, 3) if diff_before_pct else None,
                                diff_after_pct=round(diff_after_pct, 3) if diff_after_pct else None,
                                flagged_before=flag_before,
                                flagged_after=flag_after,
                                frames_checked_before=len(before_areas),
                                frames_checked_after=len(after_areas)
                            )

                            embryo_data.setdefault("flags", {}) \
                                       .setdefault("HIGH_SEGMENTATION_VAR_SNIP", []) \
                                       .append(flag_data)
        
        if self.verbose:
            print(f"   â± check_segmentation_variability {time() - t0:.2f}s")

    def check_mask_on_edge(self, author: str, entities: Dict[str, List[str]], 
                          config: Optional[Dict] = None):
        """
        Flag masks that touch image edges.
        PRESERVED: Original algorithm and performance
        ENHANCED: Flag validation and config support
        """
        if self.verbose:
            print("ðŸ–¼ï¸  Checking masks on image edge...")

        target_snips = set(entities.get("snip_ids", []))
        cfg = config or {}
        margin_pixels = cfg.get('margin_pixels', EMBRYO_INTEGRITY_FLAGS['MASK_ON_EDGE']['margin_pixels'])
        
        t0 = time()

        experiments_items = list(self.gsam_data.get("experiments", {}).items())
        for exp_id, exp_data in self._progress_iter(experiments_items, desc="Edge", total=len(experiments_items)):
            if exp_id not in entities.get("experiment_ids", []):
                continue

            for video_id, video_data in exp_data.get("videos", {}).items():
                if video_id not in entities.get("video_ids", []):
                    continue

                for image_id, image_data in video_data.get("images", {}).items():
                    if image_id not in entities.get("image_ids", []):
                        continue

                    # Infer width & height from first embryo's segmentation.size (PRESERVED)
                    height = width = None
                    sample_embryo = next(iter(image_data.get("embryos", {}).values()), None)
                    if sample_embryo and isinstance(sample_embryo.get("segmentation"), dict):
                        sz = sample_embryo["segmentation"].get("size")  # [h, w]
                        if sz and len(sz) == 2:
                            height, width = sz

                    # Fallback to normalized margin (PRESERVED)
                    norm_margin = 0.01
                    if width and height:
                        norm_margin_x = margin_pixels / width
                        norm_margin_y = margin_pixels / height
                    else:
                        norm_margin_x = norm_margin_y = norm_margin

                    for embryo_id, embryo_data in image_data["embryos"].items():
                        snip_id = embryo_data.get("snip_id")
                        if snip_id and snip_id not in target_snips:
                            continue

                        bbox = embryo_data.get("bbox")
                        if not (bbox and len(bbox) == 4):
                            continue

                        x_min, y_min, x_max, y_max = bbox

                        # Normalize bbox if needed (PRESERVED ALGORITHM)
                        if (x_max > 1 or y_max > 1) and width and height:
                            x_min /= width
                            x_max /= width
                            y_min /= height
                            y_max /= height

                        near_edge = (
                            x_min <= norm_margin_x or
                            y_min <= norm_margin_y or
                            (1 - x_max) <= norm_margin_x or
                            (1 - y_max) <= norm_margin_y
                        )

                        if near_edge:
                            # ENHANCED: Use structured flag creation
                            flag_data = create_flag_entry(
                                'MASK_ON_EDGE',
                                'embryo_integrity',
                                author,
                                image_id=image_id,
                                bbox_norm=[round(x_min, 4), round(y_min, 4),
                                          round(x_max, 4), round(y_max, 4)],
                                margin_norm=round(max(norm_margin_x, norm_margin_y), 4)
                            )
                            
                            embryo_data.setdefault("flags", {}) \
                                       .setdefault("MASK_ON_EDGE", []) \
                                       .append(flag_data)
        
        if self.verbose:
            print(f"   â± check_mask_on_edge {time() - t0:.2f}s")

    # ========================================
    # ADDITIONAL QC CHECKS (PRESERVED ALGORITHMS + ENHANCED VALIDATION)
    # ========================================
    
    def check_detection_failure(self, author: str, entities: Dict[str, List[str]], 
                               config: Optional[Dict] = None):
        """Flag images where expected embryos are missing."""
        # PRESERVED ALGORITHM + ENHANCED VALIDATION
        # [Implementation preserved from original with flag validation added]
        pass

    def check_overlapping_masks(self, author: str, entities: Dict[str, List[str]], 
                               config: Optional[Dict] = None):
        """Flag images where embryo masks overlap."""
        # PRESERVED ALGORITHM + ENHANCED VALIDATION  
        # [Implementation preserved from original with flag validation added]
        pass

    def check_large_masks(self, author: str, entities: Dict[str, List[str]], 
                         config: Optional[Dict] = None):
        """Flag unusually large masks."""
        # PRESERVED ALGORITHM + ENHANCED VALIDATION
        # [Implementation preserved from original with flag validation added]
        pass

    def check_discontinuous_masks(self, author: str, entities: Dict[str, List[str]], 
                                 config: Optional[Dict] = None):
        """Flag masks with multiple disconnected components."""
        # PRESERVED ALGORITHM + ENHANCED VALIDATION
        # [Implementation preserved from original with flag validation added]
        pass

    # ========================================
    # OVERVIEW & SAVING (PRESERVED FROM ORIGINAL)
    # ========================================
    
    def generate_overview(self, entities: Dict[str, List[str]]):
        """Generate GEN_flag_overview section with flagged entity IDs."""
        # [PRESERVED IMPLEMENTATION FROM ORIGINAL]
        pass
        
    def _save_qc_summary(self, author: str):
        """Save QC summary and write updated GSAM file.""" 
        # [PRESERVED IMPLEMENTATION FROM ORIGINAL]
        pass
        
    def _count_flags_in_hierarchy(self) -> Dict[str, int]:
        """Count new flags added in this run."""
        # [PRESERVED IMPLEMENTATION FROM ORIGINAL]
        pass
        
    def get_flags_summary(self) -> Dict:
        """Get summary of all QC flags."""
        # [PRESERVED IMPLEMENTATION FROM ORIGINAL]
        pass
        
    def print_summary(self):
        """Print a summary of QC results."""
        # [PRESERVED IMPLEMENTATION FROM ORIGINAL]
        pass

    # ========================================
    # HELPER METHODS (PRESERVED FROM ORIGINAL)
    # ========================================
    
    def _calculate_bbox_overlap(self, bbox1, bbox2) -> float:
        """Calculate IoU between two bounding boxes."""
        # [PRESERVED IMPLEMENTATION FROM ORIGINAL]
        pass
    
    def _check_mask_discontinuity(self, segmentation) -> bool:
        """Check for multiple disconnected components."""
        # [PRESERVED IMPLEMENTATION FROM ORIGINAL]  
        pass
    
    def _check_single_mask_discontinuity(self, segmentation) -> bool:
        """Check a single mask for discontinuity."""
        # [PRESERVED IMPLEMENTATION FROM ORIGINAL]
        pass
    
    def _has_multiple_components(self, mask_array) -> bool:
        """Check binary mask for >1 connected component."""
        # [PRESERVED IMPLEMENTATION FROM ORIGINAL]
        pass
```

### 4. Create `utils/qc/__init__.py`

```python
"""
QC Module: Unified quality control system.
Maintains strict separation between image and embryo integrity QC.
"""

from .qc_flags import (
    IMAGE_INTEGRITY_FLAGS,
    EMBRYO_INTEGRITY_FLAGS, 
    MANUAL_FLAGS,
    ALL_FLAGS,
    validate_flag,
    create_flag_entry,
    get_flag_info,
    get_flags_by_level
)

from .image_qc import ImageQualityAnalyzer
from .embryo_qc import EmbryoSegmentationQC

__all__ = [
    # Flag system
    'IMAGE_INTEGRITY_FLAGS',
    'EMBRYO_INTEGRITY_FLAGS',
    'MANUAL_FLAGS', 
    'ALL_FLAGS',
    'validate_flag',
    'create_flag_entry',
    'get_flag_info',
    'get_flags_by_level',
    
    # QC classes
    'ImageQualityAnalyzer',
    'EmbryoSegmentationQC'
]

# Version info
__version__ = "1.0.0"
__author__ = "morphseq_pipeline"
```

## Implementation Steps

### Phase 1: Structure Setup (Week 1)
1. **Create new directory structure**
   ```bash
   mkdir -p utils/qc
   touch utils/qc/__init__.py
   ```

2. **Implement flag system**
   - Create `utils/qc/qc_flags.py` with structured flag definitions
   - Extract all hardcoded flag strings from original code

3. **Create image QC component**
   - Implement `utils/qc/image_qc.py` (new functionality)
   - Focus/blur detection, exposure analysis, corruption detection

### Phase 2: Refactor GSAM QC (Week 2)
1. **Copy and rename original**
   ```bash
   cp gsam_qc_class.py utils/qc/embryo_qc.py
   # Rename class: GSAMQualityControl â†’ EmbryoSegmentationQC
   ```

2. **Add flag validation to all check methods**
   - Import from qc_flags
   - Add validate_flag() calls
   - Use create_flag_entry() for structured flags

3. **Preserve all performance optimizations**
   - Keep entity tracking system
   - Keep progress reporting  
   - Keep all existing algorithms

### Phase 3: Integration & Testing (Week 3)
1. **Update pipeline scripts**
   - Import from new module structure
   - Update class names and method calls

2. **Add comprehensive tests**
   - Test flag validation
   - Test both QC classes independently 
   - Test integration points

3. **Update documentation**
   - API documentation
   - Usage examples
   - Migration guide

## What You Keep vs What You Gain

### âœ… PRESERVED (Don't Fix What Works)
- **Entity tracking system** - Your performance optimization
- **Progress reporting** - tqdm integration and tmux compatibility
- **All existing QC algorithms** - They work correctly
- **GSAM JSON storage** - Direct flag writing to annotations  
- **Overview generation** - Summary and reporting functionality
- **Batch processing** - Efficient handling of large datasets

### ðŸ†• GAINED (Module 4 Benefits)
- **Structured flag system** - Centralized definitions and validation
- **Image/Embryo separation** - Clean architectural boundaries
- **Better error handling** - Standardized flag creation and validation
- **Enhanced testability** - Modular components for unit testing
- **Configuration support** - Runtime parameter adjustment
- **Pipeline integration** - Cleaner interface for orchestration scripts

## Migration Checklist

- [ ] Create new directory structure (`utils/qc/`)
- [ ] Implement flag system (`qc_flags.py`)
- [ ] Create image QC component (`image_qc.py`)
- [ ] Refactor GSAM QC â†’ Embryo QC (`embryo_qc.py`)
- [ ] Add flag validation to all check methods
- [ ] Update pipeline scripts to use new imports
- [ ] Run tests to verify functionality preserved
- [ ] Update documentation and examples
- [ ] Archive original `gsam_qc_class.py`

## Expected Outcome

After this refactoring, you will have:

1. **A superior QC architecture** that maintains strict separation between image and embryo integrity checks
2. **All existing functionality preserved** with performance optimizations intact
3. **Enhanced maintainability** through modular design and structured flag system
4. **Better integration** with the broader morphseq pipeline
5. **Future-ready foundation** for additional QC checks and visualization components

The refactored system provides the **architectural benefits of Module 4** while **preserving all the excellent work** you've already done in the original GSAM QC implementation.